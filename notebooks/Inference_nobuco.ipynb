{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to infer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_islr/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0a0+410ce96\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import Config, upload_to_kaggle\n",
    "\n",
    "from params import *\n",
    "from data.preparation import *\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from utils.metrics import *\n",
    "from utils.torch import load_model_weights\n",
    "from utils.plots import plot_sample\n",
    "from inference.main import uniform_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = \"../logs/2023-04-17/42/\"  # 0.7265 / x5 0.7273 / MTx10 0.7274\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-21/31/\"\n",
    "# EXP_FOLDER = \"../logs/2023-04-19/6/\"\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-23/27/\"   # 0.7302 / DIST 0.7341 / DISTx10 0.7310\n",
    "EXP_FOLDER = \"../logs/2023-04-23/28/\"   # 0.7295 / DIST 0.7341 / DISTx10 0.7348\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-24/9/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(DATA_PATH, config.processed_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df = df.merge(folds, how=\"left\", on=[\"participant_id\", \"sequence_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 14:19:32.224948: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tflite.prepro import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488] 1\n",
      "[522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542] 2\n",
      "[10, 54, 67, 132, 150, 152, 162, 172, 176, 234, 284, 297, 361, 379, 389, 397, 400, 454] 3\n",
      "[13, 37, 40, 61, 78, 81, 84, 87, 88, 91, 191, 267, 270, 291, 308, 311, 314, 317, 318, 321, 415] 4\n",
      "[500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511] 5\n",
      "[205, 425] 6\n",
      "\n",
      "n_landmarks : 100\n"
     ]
    }
   ],
   "source": [
    "landmarks = np.concatenate(KEPT_LANDMARKS)\n",
    "type_embed = np.zeros(1000)\n",
    "start = 0\n",
    "for subset, idx in zip(KEPT_LANDMARKS, MAPPING):\n",
    "    print(subset, idx)\n",
    "    type_embed[start: start + len(subset)] = idx\n",
    "    start += len(subset)\n",
    "\n",
    "type_embed = type_embed[type_embed > 0]\n",
    "\n",
    "type_embed = np.concatenate([type_embed, np.array([idx] * len(TO_AVG))])\n",
    "\n",
    "print(\"\\nn_landmarks :\", len(type_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENS = {\n",
    "    \"torch_12/\": 25,\n",
    "    \"torch_16/\": 30,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro = Preprocessing(type_embed, max_len=MAX_LENS[config.processed_folder], model_max_len=config.max_len)\n",
    "config.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 14:19:35.898491: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-27 14:19:35.898592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: 4532240\n",
      "2023-04-27 14:19:35.898609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: 4532240\n",
      "2023-04-27 14:19:35.898738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 520.61.5\n",
      "2023-04-27 14:19:35.898778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 515.65.1\n",
      "2023-04-27 14:19:35.898793: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:312] kernel version 515.65.1 does not match DSO version 520.61.5 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "inp = tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")\n",
    "prepro_tf = PreprocessingTF(type_embed, max_len=MAX_LENS[config.processed_folder], model_max_len=config.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9073486e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "times = []\n",
    "\n",
    "# for i in tqdm(range(len(df['path']))):\n",
    "for i in tqdm(range(100)):\n",
    "    path = df['path'][i]\n",
    "    name = f\"{path.split('/')[-2]}_{path.split('/')[-1].split('.')[0]}.npy\"\n",
    "\n",
    "    pq, data = load_relevant_data_subset(path)\n",
    "    \n",
    "    x = torch.from_numpy(data)\n",
    "    x_ = tf.constant(data)\n",
    "\n",
    "    x_torch = prepro(x)\n",
    "    x_tf = prepro_tf(x_)\n",
    "    \n",
    "    print(np.abs(x_tf.numpy() - x_torch.numpy()).max())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite.models import Model\n",
    "from utils.torch import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1024)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIST = config.mt_config['distill']\n",
    "DIST = True\n",
    "\n",
    "model = Model(\n",
    "    type_embed,\n",
    "    embed_dim=config.embed_dim,\n",
    "    transfo_dim=512 + 64, #config.transfo_dim if not DIST else 512,\n",
    "    dense_dim=192,  # config.dense_dim if not DIST else 192,\n",
    "    transfo_layers=3,  # config.transfo_layers  if not DIST else 2,\n",
    "    transfo_heads=config.transfo_heads,\n",
    "    drop_rate=config.drop_rate,\n",
    "    num_classes=config.num_classes,\n",
    "    max_len=config.max_len,\n",
    ").cpu().eval()\n",
    "\n",
    "config.embed_dim, config.transfo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6760354"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SOUP = 0\n",
    "TEACHER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> CV acc : 0.7248\n"
     ]
    }
   ],
   "source": [
    "if DIST:\n",
    "    pred_oof = np.load(EXP_FOLDER + \"pred_oof_dist.npy\")\n",
    "elif TEACHER:\n",
    "    pred_oof = np.load(EXP_FOLDER + \"pred_oof_teach.npy\")\n",
    "else:\n",
    "    try:\n",
    "        pred_oof = np.load(EXP_FOLDER + \"pred_oof_inf.npy\")\n",
    "    except:\n",
    "        pred_oof = np.load(EXP_FOLDER + \"pred_oof.npy\")\n",
    "\n",
    "score = accuracy(df['target'], pred_oof)\n",
    "print(f\"-> CV acc : {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not loading weights !\n"
     ]
    }
   ],
   "source": [
    "if N_SOUP:\n",
    "    if TEACHER:\n",
    "        weights = [EXP_FOLDER + f\"{config.name}_teacher_fullfit_0_{ep}.pt\" for ep in range(config.epochs - N_SOUP, config.epochs + 1)]\n",
    "    elif DIST:\n",
    "        weights = [EXP_FOLDER + f\"{config.name}_distilled_fullfit_0_{ep}.pt\" for ep in range(config.epochs - N_SOUP, config.epochs + 1)]\n",
    "    else:\n",
    "        weights = [EXP_FOLDER + f\"{config.name}_fullfit_0_{ep}.pt\" for ep in range(config.epochs - N_SOUP, config.epochs + 1)]\n",
    "    print(\"-> Soup :\", [w.split('/')[-1] for w in weights])\n",
    "    model = uniform_soup(model, weights)\n",
    "\n",
    "else:\n",
    "    try:\n",
    "    #     model = load_model_weights(model, EXP_FOLDER + f\"{config.name}_fullfit_0.pt\")\n",
    "    #     model = load_model_weights(model, EXP_FOLDER + f\"{config.name}_teacher_fullfit_0.pt\")\n",
    "#         model = load_model_weights(model, EXP_FOLDER + f\"{config.name}_0.pt\")\n",
    "        model = load_model_weights(model, EXP_FOLDER + f\"{config.name}_distilled_0.pt\")\n",
    "    \n",
    "#         weights = [EXP_FOLDER + f\"{config.name}_0_{ep}.pt\" for ep in range(config.epochs - 10, config.epochs + 1)]\n",
    "#         print(\"-> Soup :\", [w.split('/')[-1] for w in weights])\n",
    "#         model = uniform_soup(model, weights)\n",
    "    \n",
    "    except: # FileNotFoundError:\n",
    "        print('Not loading weights !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref val acc : 0.7002862510063512\n"
     ]
    }
   ],
   "source": [
    "df = df[df['fold'] == 0].reset_index(drop=True)\n",
    "pred_val = np.load(EXP_FOLDER + \"pred_val_0.npy\")\n",
    "print('Ref val acc :', accuracy(df['target'], pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "times = []\n",
    "\n",
    "# for i in tqdm(range(len(df['path']))):\n",
    "for i in tqdm(range(100)):\n",
    "    path = df['path'][i]\n",
    "    name = f\"{path.split('/')[-2]}_{path.split('/')[-1].split('.')[0]}.npy\"\n",
    "\n",
    "    pq, data = load_relevant_data_subset(path)\n",
    "    \n",
    "    x = torch.from_numpy(data)\n",
    "\n",
    "    t0 = time.time()\n",
    "    x = prepro(x)\n",
    "    y = model(x)\n",
    "    preds.append(y.detach().cpu().numpy().flatten())\n",
    "    t1 = time.time()\n",
    "    \n",
    "    times.append((t1 - t0) * 1000)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime : 344.7ms\n"
     ]
    }
   ],
   "source": [
    "print(f'Runtime : {np.mean(times) :.1f}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.stack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(df['target'].head(len(preds)), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nobuco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nobuco\n",
    "import tensorflow_addons as tfa\n",
    "from nobuco import ChannelOrder, ChannelOrderingStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nobuco.converter(torch.nn.functional.mish, channel_ordering_strategy=ChannelOrderingStrategy.MINIMUM_TRANSPOSITIONS)\n",
    "def mish(input: torch.Tensor, inplace: bool = False):\n",
    "    return lambda input, inplace=False: tfa.activations.mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nobuco.converter(torch.Tensor.long, channel_ordering_strategy=ChannelOrderingStrategy.MINIMUM_TRANSPOSITIONS)\n",
    "def long(input: torch.Tensor, inplace: bool = False):\n",
    "    return lambda input, inplace=False: tf.cast(input, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nobuco.converter(torch.Tensor.int, channel_ordering_strategy=ChannelOrderingStrategy.MINIMUM_TRANSPOSITIONS)\n",
    "def int(input: torch.Tensor, inplace: bool = False):\n",
    "    return lambda input, inplace=False: tf.cast(input, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nobuco.converter(torch.Tensor.amax, channel_ordering_strategy=ChannelOrderingStrategy.FORCE_PYTORCH_ORDER)\n",
    "def amax(input: torch.Tensor, dim=None, keepdim=False):\n",
    "    return lambda input, axis: tf.reduce_max(input, axis=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nobuco.converter(torch.gather, channel_ordering_strategy=ChannelOrderingStrategy.MINIMUM_TRANSPOSITIONS)\n",
    "def gather(input, dim, index):\n",
    "    return lambda input, dim, index: tf.gather(input, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nobuco.converter(torch.zeros, channel_ordering_strategy=ChannelOrderingStrategy.MINIMUM_TRANSPOSITIONS)\n",
    "def zeros(*size):\n",
    "    print(size)\n",
    "    return lambda size: tf.zeros(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 5, 100])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = df['path'][0]\n",
    "pq, data = load_relevant_data_subset(path)\n",
    "inp = torch.from_numpy(prepro_tf(data).numpy()).contiguous()\n",
    "inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mModel[tflite.models]\u001b[0m(float32_0<14,5,100>\u001b[0m) -> float32_673<1,250>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_0<14,5,100>\u001b[0m, 0) -> float32_1<1,14,5,100>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_1<1,14,5,100>\u001b[0m) -> (int32_2<>\u001b[0m, int32_3<>\u001b[0m, \u001b[90mint32_4<>\u001b[0m, int32_5<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_1<1,14,5,100>\u001b[0m, (:, :, 0)) -> float32_6<1,14,100>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mlong[torch.Tensor]\u001b[0m(float32_6<1,14,100>\u001b[0m) -> int64_7<1,14,100>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mEmbedding[torch.nn.modules.sparse]\u001b[0m(int64_7<1,14,100>\u001b[0m) -> float32_9<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1membedding[torch.nn.functional]\u001b[0m(int64_7<1,14,100>\u001b[0m, \u001b[4mfloat32_8<9,16>\u001b[0m, 0, None, 2.0, False, False) -> float32_9<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0membedding[torch]\u001b[0m(float32_8<9,16>\u001b[0m, int64_7<1,14,100>\u001b[0m, 0, False, False) -> float32_9<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(float32_9<1,14,100,16>\u001b[0m) -> float32_12<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_9<1,14,100,16>\u001b[0m, (16), \u001b[4mfloat32_10<16>\u001b[0m, \u001b[4mfloat32_11<16>\u001b[0m, 1e-05) -> float32_12<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_9<1,14,100,16>\u001b[0m, (16), float32_10<16>\u001b[0m, float32_11<16>\u001b[0m, 1e-05, True) -> float32_12<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_1<1,14,5,100>\u001b[0m, (:, :, 4)) -> float32_13<1,14,100>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mlong[torch.Tensor]\u001b[0m(float32_13<1,14,100>\u001b[0m) -> int64_14<1,14,100>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mEmbedding[torch.nn.modules.sparse]\u001b[0m(int64_14<1,14,100>\u001b[0m) -> float32_16<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1membedding[torch.nn.functional]\u001b[0m(int64_14<1,14,100>\u001b[0m, \u001b[4mfloat32_15<101,16>\u001b[0m, 0, None, 2.0, False, False) -> float32_16<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0membedding[torch]\u001b[0m(float32_15<101,16>\u001b[0m, int64_14<1,14,100>\u001b[0m, 0, False, False) -> float32_16<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(float32_16<1,14,100,16>\u001b[0m) -> float32_19<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_16<1,14,100,16>\u001b[0m, (16), \u001b[4mfloat32_17<16>\u001b[0m, \u001b[4mfloat32_18<16>\u001b[0m, 1e-05) -> float32_19<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_16<1,14,100,16>\u001b[0m, (16), float32_17<16>\u001b[0m, float32_18<16>\u001b[0m, 1e-05, True) -> float32_19<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_1<1,14,5,100>\u001b[0m, (:, :, 1:4)) -> float32_20<1,14,3,100>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_20<1,14,3,100>\u001b[0m, 2, 3) -> float32_21<1,14,100,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_21<1,14,100,3>\u001b[0m) -> float32_22<1,14,100,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpad[torch.nn.functional]\u001b[0m(float32_22<1,14,100,3>\u001b[0m, (0, 0, 0, 0, 0, 2)) -> float32_23<1,16,100,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_23<1,16,100,3>\u001b[0m, 1, 2) -> float32_24<1,100,16,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_24<1,100,16,3>\u001b[0m, 2, 3) -> float32_25<1,100,3,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_25<1,100,3,16>\u001b[0m) -> float32_26<1,100,3,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(int32_2<>\u001b[0m, int32_5<>\u001b[0m) -> int32_27<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_26<1,100,3,16>\u001b[0m, int32_27<>\u001b[0m, 3, -1) -> float32_28<100,3,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_28<100,3,16>\u001b[0m) -> float32_32<100,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv1d[torch.nn.modules.conv]\u001b[0m(float32_28<100,3,16>\u001b[0m) -> float32_30<100,8,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv1d[torch.nn.functional]\u001b[0m(float32_28<100,3,16>\u001b[0m, float32_29<8,3,5>\u001b[0m, None, (1), (2), (1), 1) -> float32_30<100,8,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv1d[torch.nn.modules.conv]\u001b[0m(float32_30<100,8,16>\u001b[0m) -> float32_32<100,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv1d[torch.nn.functional]\u001b[0m(float32_30<100,8,16>\u001b[0m, float32_31<16,8,5>\u001b[0m, None, (1), (2), (1), 1) -> float32_32<100,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_32<100,16,16>\u001b[0m, int32_2<>\u001b[0m, int32_5<>\u001b[0m, 16, -1) -> float32_33<1,100,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_33<1,100,16,16>\u001b[0m, 2, 3) -> float32_34<1,100,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_34<1,100,16,16>\u001b[0m, 1, 2) -> float32_35<1,16,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_35<1,16,100,16>\u001b[0m) -> float32_36<1,16,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_23<1,16,100,3>\u001b[0m, float32_36<1,16,100,16>\u001b[0m], -1) -> float32_37<1,16,100,19>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_37<1,16,100,19>\u001b[0m, (:, :-2)) -> float32_38<1,14,100,19>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_38<1,14,100,19>\u001b[0m) -> float32_41<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_38<1,14,100,19>\u001b[0m, float32_39<16,19>\u001b[0m, float32_40<16>\u001b[0m) -> float32_41<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_12<1,14,100,16>\u001b[0m, float32_19<1,14,100,16>\u001b[0m, float32_41<1,14,100,16>\u001b[0m], -1) -> float32_42<1,14,100,48>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_42<1,14,100,48>\u001b[0m) -> float32_45<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_42<1,14,100,48>\u001b[0m, float32_43<16,48>\u001b[0m, float32_44<16>\u001b[0m) -> float32_45<1,14,100,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_1<1,14,5,100>\u001b[0m, (:, :, 0)) -> float32_46<1,14,100>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_46<1,14,100>\u001b[0m) -> float32_47<1,14,100>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_47<1,14,100>\u001b[0m, 1) -> float32_48<1,1,14,100>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_48<1,1,14,100>\u001b[0m, -1) -> float32_49<1400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mlong[torch.Tensor]\u001b[0m(float32_49<1400>\u001b[0m) -> int64_50<1400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_45<1,14,100,16>\u001b[0m, -1, 16) -> float32_51<1400,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__eq__[torch.Tensor]\u001b[0m(int64_50<1400>\u001b[0m, 1) -> bool_52<1400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_51<1400,16>\u001b[0m, bool_52<1400>\u001b[0m) -> float32_53<294,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_53<294,16>\u001b[0m, -1, 336) -> float32_54<14,336>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_54<14,336>\u001b[0m) -> float32_63<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_54<14,336>\u001b[0m) -> float32_57<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_54<14,336>\u001b[0m, float32_55<192,336>\u001b[0m, float32_56<192>\u001b[0m) -> float32_57<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_57<14,192>\u001b[0m) -> float32_62<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_57<14,192>\u001b[0m, float32_58<192>\u001b[0m, float32_59<192>\u001b[0m, float32_60<192>\u001b[0m, float32_61<192>\u001b[0m, False, 0.1, 1e-05) -> float32_62<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_57<14,192>\u001b[0m, float32_60<192>\u001b[0m, float32_61<192>\u001b[0m, float32_58<192>\u001b[0m, float32_59<192>\u001b[0m, False, 0.1, 1e-05, True) -> float32_62<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_62<14,192>\u001b[0m) -> float32_62<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_62<14,192>\u001b[0m, 0.05, False, False) -> float32_62<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMish[torch.nn.modules.activation]\u001b[0m(float32_62<14,192>\u001b[0m) -> float32_63<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmish[torch.nn.functional]\u001b[0m(float32_62<14,192>\u001b[0m, inplace=False) -> float32_63<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_45<1,14,100,16>\u001b[0m, -1, 16) -> float32_64<1400,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__eq__[torch.Tensor]\u001b[0m(int64_50<1400>\u001b[0m, 2) -> bool_65<1400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_64<1400,16>\u001b[0m, bool_65<1400>\u001b[0m) -> float32_66<294,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_66<294,16>\u001b[0m, -1, 336) -> float32_67<14,336>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_67<14,336>\u001b[0m) -> float32_76<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_67<14,336>\u001b[0m) -> float32_70<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_67<14,336>\u001b[0m, float32_68<192,336>\u001b[0m, float32_69<192>\u001b[0m) -> float32_70<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_70<14,192>\u001b[0m) -> float32_75<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_70<14,192>\u001b[0m, float32_71<192>\u001b[0m, float32_72<192>\u001b[0m, float32_73<192>\u001b[0m, float32_74<192>\u001b[0m, False, 0.1, 1e-05) -> float32_75<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_70<14,192>\u001b[0m, float32_73<192>\u001b[0m, float32_74<192>\u001b[0m, float32_71<192>\u001b[0m, float32_72<192>\u001b[0m, False, 0.1, 1e-05, True) -> float32_75<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_75<14,192>\u001b[0m) -> float32_75<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_75<14,192>\u001b[0m, 0.05, False, False) -> float32_75<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMish[torch.nn.modules.activation]\u001b[0m(float32_75<14,192>\u001b[0m) -> float32_76<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmish[torch.nn.functional]\u001b[0m(float32_75<14,192>\u001b[0m, inplace=False) -> float32_76<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mstack[torch]\u001b[0m([float32_63<14,192>\u001b[0m, float32_76<14,192>\u001b[0m], -1) -> float32_77<14,192,2>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mamax[torch.Tensor]\u001b[0m(float32_77<14,192,2>\u001b[0m, -1) -> float32_78<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_45<1,14,100,16>\u001b[0m, -1, 16) -> float32_79<1400,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__eq__[torch.Tensor]\u001b[0m(int64_50<1400>\u001b[0m, 4) -> bool_80<1400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_79<1400,16>\u001b[0m, bool_80<1400>\u001b[0m) -> float32_81<294,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_81<294,16>\u001b[0m, -1, 336) -> float32_82<14,336>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_82<14,336>\u001b[0m) -> float32_91<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_82<14,336>\u001b[0m) -> float32_85<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_82<14,336>\u001b[0m, float32_83<192,336>\u001b[0m, float32_84<192>\u001b[0m) -> float32_85<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_85<14,192>\u001b[0m) -> float32_90<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_85<14,192>\u001b[0m, float32_86<192>\u001b[0m, float32_87<192>\u001b[0m, float32_88<192>\u001b[0m, float32_89<192>\u001b[0m, False, 0.1, 1e-05) -> float32_90<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_85<14,192>\u001b[0m, float32_88<192>\u001b[0m, float32_89<192>\u001b[0m, float32_86<192>\u001b[0m, float32_87<192>\u001b[0m, False, 0.1, 1e-05, True) -> float32_90<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_90<14,192>\u001b[0m) -> float32_90<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_90<14,192>\u001b[0m, 0.05, False, False) -> float32_90<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMish[torch.nn.modules.activation]\u001b[0m(float32_90<14,192>\u001b[0m) -> float32_91<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmish[torch.nn.functional]\u001b[0m(float32_90<14,192>\u001b[0m, inplace=False) -> float32_91<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_45<1,14,100,16>\u001b[0m, -1, 16) -> float32_92<1400,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__eq__[torch.Tensor]\u001b[0m(int64_50<1400>\u001b[0m, 3) -> bool_93<1400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__eq__[torch.Tensor]\u001b[0m(int64_50<1400>\u001b[0m, 6) -> bool_94<1400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__or__[torch.Tensor]\u001b[0m(bool_93<1400>\u001b[0m, bool_94<1400>\u001b[0m) -> bool_95<1400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_92<1400,16>\u001b[0m, bool_95<1400>\u001b[0m) -> float32_96<350,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_96<350,16>\u001b[0m, -1, 400) -> float32_97<14,400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_97<14,400>\u001b[0m) -> float32_106<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_97<14,400>\u001b[0m) -> float32_100<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_97<14,400>\u001b[0m, float32_98<192,400>\u001b[0m, float32_99<192>\u001b[0m) -> float32_100<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_100<14,192>\u001b[0m) -> float32_105<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_100<14,192>\u001b[0m, float32_101<192>\u001b[0m, float32_102<192>\u001b[0m, float32_103<192>\u001b[0m, float32_104<192>\u001b[0m, False, 0.1, 1e-05) -> float32_105<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_100<14,192>\u001b[0m, float32_103<192>\u001b[0m, float32_104<192>\u001b[0m, float32_101<192>\u001b[0m, float32_102<192>\u001b[0m, False, 0.1, 1e-05, True) -> float32_105<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_105<14,192>\u001b[0m) -> float32_105<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_105<14,192>\u001b[0m, 0.05, False, False) -> float32_105<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMish[torch.nn.modules.activation]\u001b[0m(float32_105<14,192>\u001b[0m) -> float32_106<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmish[torch.nn.functional]\u001b[0m(float32_105<14,192>\u001b[0m, inplace=False) -> float32_106<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__rmul__[torch.Tensor]\u001b[0m(int32_5<>\u001b[0m, 16) -> int32_107<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_45<1,14,100,16>\u001b[0m, -1, int32_107<>\u001b[0m) -> float32_108<14,1600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_108<14,1600>\u001b[0m) -> float32_117<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_108<14,1600>\u001b[0m) -> float32_111<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_108<14,1600>\u001b[0m, float32_109<192,1600>\u001b[0m, float32_110<192>\u001b[0m) -> float32_111<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_111<14,192>\u001b[0m) -> float32_116<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_111<14,192>\u001b[0m, float32_112<192>\u001b[0m, float32_113<192>\u001b[0m, float32_114<192>\u001b[0m, float32_115<192>\u001b[0m, False, 0.1, 1e-05) -> float32_116<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_111<14,192>\u001b[0m, float32_114<192>\u001b[0m, float32_115<192>\u001b[0m, float32_112<192>\u001b[0m, float32_113<192>\u001b[0m, False, 0.1, 1e-05, True) -> float32_116<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_116<14,192>\u001b[0m) -> float32_116<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_116<14,192>\u001b[0m, 0.05, False, False) -> float32_116<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMish[torch.nn.modules.activation]\u001b[0m(float32_116<14,192>\u001b[0m) -> float32_117<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmish[torch.nn.functional]\u001b[0m(float32_116<14,192>\u001b[0m, inplace=False) -> float32_117<14,192>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_117<14,192>\u001b[0m, float32_78<14,192>\u001b[0m, float32_91<14,192>\u001b[0m, float32_106<14,192>\u001b[0m], -1) -> float32_118<14,768>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_118<14,768>\u001b[0m) -> float32_127<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_118<14,768>\u001b[0m) -> float32_121<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_118<14,768>\u001b[0m, float32_119<512,768>\u001b[0m, float32_120<512>\u001b[0m) -> float32_121<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_121<14,512>\u001b[0m) -> float32_126<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_121<14,512>\u001b[0m, float32_122<512>\u001b[0m, float32_123<512>\u001b[0m, float32_124<512>\u001b[0m, float32_125<512>\u001b[0m, False, 0.1, 1e-05) -> float32_126<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_121<14,512>\u001b[0m, float32_124<512>\u001b[0m, float32_125<512>\u001b[0m, float32_122<512>\u001b[0m, float32_123<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_126<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_126<14,512>\u001b[0m) -> float32_126<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_126<14,512>\u001b[0m, 0.05, False, False) -> float32_126<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMish[torch.nn.modules.activation]\u001b[0m(float32_126<14,512>\u001b[0m) -> float32_127<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmish[torch.nn.functional]\u001b[0m(float32_126<14,512>\u001b[0m, inplace=False) -> float32_127<14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_127<14,512>\u001b[0m, int32_2<>\u001b[0m, -1, 512) -> \u001b[90mfloat32_128<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__sub__[torch.Tensor]\u001b[0m(int32_3<>\u001b[0m, 1) -> int32_129<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(\u001b[4mint32_130<25,1,25,25>\u001b[0m, (int32_129<>\u001b[0m, :, :int32_3<>\u001b[0m, :int32_3<>\u001b[0m)) -> int32_131<1,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(int32_131<1,14,14>\u001b[0m) -> int32_132<1,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__sub__[torch.Tensor]\u001b[0m(int32_3<>\u001b[0m, 1) -> int32_133<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(\u001b[4mint32_134<25,1,25,25>\u001b[0m, (int32_133<>\u001b[0m, :, :int32_3<>\u001b[0m, :int32_3<>\u001b[0m)) -> int32_135<1,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(int32_135<1,14,14>\u001b[0m) -> int32_136<1,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(\u001b[4mint32_137<16>\u001b[0m, 1) -> int32_138<16,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(int32_138<16,1>\u001b[0m, 1) -> int32_139<16,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(int32_139<16,1,1>\u001b[0m, int32_3<>\u001b[0m) -> int32_140<16,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(int32_136<1,14,14>\u001b[0m, int32_140<16,1,1>\u001b[0m) -> int32_141<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(int32_141<16,14,14>\u001b[0m, -1) -> int32_142<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(int32_132<1,14,14>\u001b[0m, int32_140<16,1,1>\u001b[0m) -> int32_143<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(int32_143<16,14,14>\u001b[0m, -1) -> int32_144<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mDebertaV2Encoder[tflite.deberta]\u001b[0m(float32_128<1,14,512>\u001b[0m, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> {\"last_hidden_state\": \u001b[90mfloat32_319<1,14,576>\u001b[0m, \"hidden_states\": (\u001b[90mfloat32_128<1,14,512>\u001b[0m, \u001b[90mfloat32_319<1,14,576>\u001b[0m)}\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(\u001b[4mfloat32_145<50,512>\u001b[0m) -> float32_148<50,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_145<50,512>\u001b[0m, (512), \u001b[4mfloat32_146<512>\u001b[0m, \u001b[4mfloat32_147<512>\u001b[0m, 1e-07) -> float32_148<50,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_145<50,512>\u001b[0m, (512), float32_146<512>\u001b[0m, float32_147<512>\u001b[0m, 1e-07, True) -> float32_148<50,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mDebertaV2Layer[tflite.deberta]\u001b[0m(float32_128<1,14,512>\u001b[0m, query_states=None, relative_pos=None, rel_embeddings=float32_148<50,512>\u001b[0m, output_attentions=False, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> float32_319<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDebertaV2Attention[tflite.deberta]\u001b[0m(float32_128<1,14,512>\u001b[0m, output_attentions=False, query_states=None, relative_pos=None, rel_embeddings=float32_148<50,512>\u001b[0m, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> float32_308<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDisentangledSelfAttention[tflite.deberta]\u001b[0m(float32_128<1,14,512>\u001b[0m, False, query_states=None, relative_pos=None, rel_embeddings=float32_148<50,512>\u001b[0m, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> float32_301<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_128<1,14,512>\u001b[0m) -> float32_151<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_128<1,14,512>\u001b[0m, float32_149<512,512>\u001b[0m, float32_150<512>\u001b[0m) -> float32_151<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_151<1,14,512>\u001b[0m) -> (int32_152<>\u001b[0m, int32_153<>\u001b[0m, \u001b[90mint32_154<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_151<1,14,512>\u001b[0m, (int32_152<>\u001b[0m, int32_153<>\u001b[0m, 16, -1)) -> float32_155<1,14,16,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_155<1,14,16,32>\u001b[0m, 0, 2, 1, 3) -> float32_156<1,16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_156<1,16,14,32>\u001b[0m) -> float32_157<1,16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_155<1,14,16,32>\u001b[0m) -> (\u001b[90mint32_158<>\u001b[0m, int32_159<>\u001b[0m, \u001b[90mint32_160<>\u001b[0m, \u001b[90mint32_161<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_155<1,14,16,32>\u001b[0m) -> (\u001b[90mint32_162<>\u001b[0m, \u001b[90mint32_163<>\u001b[0m, \u001b[90mint32_164<>\u001b[0m, int32_165<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_157<1,16,14,32>\u001b[0m, -1, int32_159<>\u001b[0m, int32_165<>\u001b[0m) -> float32_166<16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_128<1,14,512>\u001b[0m) -> float32_169<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_128<1,14,512>\u001b[0m, float32_167<512,512>\u001b[0m, float32_168<512>\u001b[0m) -> float32_169<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_169<1,14,512>\u001b[0m) -> (int32_170<>\u001b[0m, int32_171<>\u001b[0m, \u001b[90mint32_172<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_169<1,14,512>\u001b[0m, (int32_170<>\u001b[0m, int32_171<>\u001b[0m, 16, -1)) -> float32_173<1,14,16,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_173<1,14,16,32>\u001b[0m, 0, 2, 1, 3) -> float32_174<1,16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_174<1,16,14,32>\u001b[0m) -> float32_175<1,16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_173<1,14,16,32>\u001b[0m) -> (\u001b[90mint32_176<>\u001b[0m, int32_177<>\u001b[0m, \u001b[90mint32_178<>\u001b[0m, \u001b[90mint32_179<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_173<1,14,16,32>\u001b[0m) -> (\u001b[90mint32_180<>\u001b[0m, \u001b[90mint32_181<>\u001b[0m, \u001b[90mint32_182<>\u001b[0m, int32_183<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_175<1,16,14,32>\u001b[0m, -1, int32_177<>\u001b[0m, int32_183<>\u001b[0m) -> float32_184<16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_128<1,14,512>\u001b[0m) -> float32_187<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_128<1,14,512>\u001b[0m, float32_185<512,512>\u001b[0m, float32_186<512>\u001b[0m) -> float32_187<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_187<1,14,512>\u001b[0m) -> (int32_188<>\u001b[0m, int32_189<>\u001b[0m, \u001b[90mint32_190<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_187<1,14,512>\u001b[0m, (int32_188<>\u001b[0m, int32_189<>\u001b[0m, 16, -1)) -> float32_191<1,14,16,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_191<1,14,16,32>\u001b[0m, 0, 2, 1, 3) -> float32_192<1,16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_192<1,16,14,32>\u001b[0m) -> float32_193<1,16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_191<1,14,16,32>\u001b[0m) -> (\u001b[90mint32_194<>\u001b[0m, int32_195<>\u001b[0m, \u001b[90mint32_196<>\u001b[0m, \u001b[90mint32_197<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_191<1,14,16,32>\u001b[0m) -> (\u001b[90mint32_198<>\u001b[0m, \u001b[90mint32_199<>\u001b[0m, \u001b[90mint32_200<>\u001b[0m, int32_201<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_193<1,16,14,32>\u001b[0m, -1, int32_195<>\u001b[0m, int32_201<>\u001b[0m) -> float32_202<16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_203<>\u001b[0m, 3) -> float32_204<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msqrt[torch]\u001b[0m(float32_204<>\u001b[0m) -> float32_205<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_184<16,14,32>\u001b[0m, -1, -2) -> float32_206<16,32,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_166<16,14,32>\u001b[0m, float32_206<16,32,14>\u001b[0m) -> float32_207<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_207<16,14,14>\u001b[0m, float32_205<>\u001b[0m) -> float32_208<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_148<50,512>\u001b[0m, (0:50, :)) -> float32_209<50,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_209<50,512>\u001b[0m, 0) -> float32_210<1,50,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*Linear[torch.nn.modules.linear]\u001b[0m(float32_210<1,50,512>\u001b[0m) -> float32_211<1,50,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_211<1,50,512>\u001b[0m) -> (int32_212<>\u001b[0m, int32_213<>\u001b[0m, \u001b[90mint32_214<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_211<1,50,512>\u001b[0m, (int32_212<>\u001b[0m, int32_213<>\u001b[0m, 16, -1)) -> float32_215<1,50,16,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_215<1,50,16,32>\u001b[0m, 0, 2, 1, 3) -> float32_216<1,16,50,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_216<1,16,50,32>\u001b[0m) -> float32_217<1,16,50,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_215<1,50,16,32>\u001b[0m) -> (\u001b[90mint32_218<>\u001b[0m, int32_219<>\u001b[0m, \u001b[90mint32_220<>\u001b[0m, \u001b[90mint32_221<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_215<1,50,16,32>\u001b[0m) -> (\u001b[90mint32_222<>\u001b[0m, \u001b[90mint32_223<>\u001b[0m, \u001b[90mint32_224<>\u001b[0m, int32_225<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_217<1,16,50,32>\u001b[0m, -1, int32_219<>\u001b[0m, int32_225<>\u001b[0m) -> float32_226<16,50,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*Linear[torch.nn.modules.linear]\u001b[0m(float32_210<1,50,512>\u001b[0m) -> float32_227<1,50,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_227<1,50,512>\u001b[0m) -> (int32_228<>\u001b[0m, int32_229<>\u001b[0m, \u001b[90mint32_230<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_227<1,50,512>\u001b[0m, (int32_228<>\u001b[0m, int32_229<>\u001b[0m, 16, -1)) -> float32_231<1,50,16,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_231<1,50,16,32>\u001b[0m, 0, 2, 1, 3) -> float32_232<1,16,50,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_232<1,16,50,32>\u001b[0m) -> float32_233<1,16,50,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_231<1,50,16,32>\u001b[0m) -> (\u001b[90mint32_234<>\u001b[0m, int32_235<>\u001b[0m, \u001b[90mint32_236<>\u001b[0m, \u001b[90mint32_237<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_231<1,50,16,32>\u001b[0m) -> (\u001b[90mint32_238<>\u001b[0m, \u001b[90mint32_239<>\u001b[0m, \u001b[90mint32_240<>\u001b[0m, int32_241<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_233<1,16,50,32>\u001b[0m, -1, int32_235<>\u001b[0m, int32_241<>\u001b[0m) -> float32_242<16,50,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_203<>\u001b[0m, 3) -> float32_243<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msqrt[torch]\u001b[0m(float32_243<>\u001b[0m) -> float32_244<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_242<16,50,32>\u001b[0m, -1, -2) -> float32_245<16,32,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_166<16,14,32>\u001b[0m, float32_245<16,32,50>\u001b[0m) -> float32_246<16,14,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_246<16,14,50>\u001b[0m) -> (int32_247<>\u001b[0m, int32_248<>\u001b[0m, \u001b[90mint32_249<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_246<16,14,50>\u001b[0m, -1) -> float32_250<11200>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSelector[tflite.deberta]\u001b[0m(float32_250<11200>\u001b[0m, int32_142<3136>\u001b[0m) -> float32_252<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mlong[torch.Tensor]\u001b[0m(int32_142<3136>\u001b[0m) -> int64_251<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_250<11200>\u001b[0m, 0, int64_251<3136>\u001b[0m) -> float32_252<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_252<3136>\u001b[0m, int32_247<>\u001b[0m, int32_248<>\u001b[0m, int32_248<>\u001b[0m) -> float32_253<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_253<16,14,14>\u001b[0m, float32_244<>\u001b[0m) -> float32_254<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__radd__[torch.Tensor]\u001b[0m(float32_254<16,14,14>\u001b[0m, 0) -> float32_255<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_203<>\u001b[0m, 3) -> float32_256<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msqrt[torch]\u001b[0m(float32_256<>\u001b[0m) -> float32_257<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_226<16,50,32>\u001b[0m, -1, -2) -> float32_258<16,32,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_184<16,14,32>\u001b[0m, float32_258<16,32,50>\u001b[0m) -> float32_259<16,14,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_259<16,14,50>\u001b[0m) -> (int32_260<>\u001b[0m, int32_261<>\u001b[0m, \u001b[90mint32_262<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_259<16,14,50>\u001b[0m, -1) -> float32_263<11200>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSelector[tflite.deberta]\u001b[0m(float32_263<11200>\u001b[0m, int32_144<3136>\u001b[0m) -> float32_265<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mlong[torch.Tensor]\u001b[0m(int32_144<3136>\u001b[0m) -> int64_264<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_263<11200>\u001b[0m, 0, int64_264<3136>\u001b[0m) -> float32_265<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_265<3136>\u001b[0m, int32_260<>\u001b[0m, int32_261<>\u001b[0m, int32_261<>\u001b[0m) -> float32_266<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_266<16,14,14>\u001b[0m, -1, -2) -> float32_267<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_267<16,14,14>\u001b[0m, float32_257<>\u001b[0m) -> float32_268<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_255<16,14,14>\u001b[0m, float32_268<16,14,14>\u001b[0m) -> float32_255<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_208<16,14,14>\u001b[0m, float32_255<16,14,14>\u001b[0m) -> float32_269<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_269<16,14,14>\u001b[0m) -> (\u001b[90mint32_270<>\u001b[0m, int32_271<>\u001b[0m, \u001b[90mint32_272<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_269<16,14,14>\u001b[0m) -> (\u001b[90mint32_273<>\u001b[0m, \u001b[90mint32_274<>\u001b[0m, int32_275<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_269<16,14,14>\u001b[0m, -1, 16, int32_271<>\u001b[0m, int32_275<>\u001b[0m) -> float32_276<1,16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch]\u001b[0m(float32_276<1,16,14,14>\u001b[0m, -1) -> float32_277<1,16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_277<1,16,14,14>\u001b[0m) -> (\u001b[90mint32_278<>\u001b[0m, \u001b[90mint32_279<>\u001b[0m, int32_280<>\u001b[0m, \u001b[90mint32_281<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_277<1,16,14,14>\u001b[0m) -> (\u001b[90mint32_282<>\u001b[0m, \u001b[90mint32_283<>\u001b[0m, \u001b[90mint32_284<>\u001b[0m, int32_285<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_277<1,16,14,14>\u001b[0m, -1, int32_280<>\u001b[0m, int32_285<>\u001b[0m) -> float32_286<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_286<16,14,14>\u001b[0m, float32_202<16,14,32>\u001b[0m) -> float32_287<16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_287<16,14,32>\u001b[0m) -> (\u001b[90mint32_288<>\u001b[0m, int32_289<>\u001b[0m, \u001b[90mint32_290<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_287<16,14,32>\u001b[0m) -> (\u001b[90mint32_291<>\u001b[0m, \u001b[90mint32_292<>\u001b[0m, int32_293<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_287<16,14,32>\u001b[0m, -1, 16, int32_289<>\u001b[0m, int32_293<>\u001b[0m) -> float32_294<1,16,14,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_294<1,16,14,32>\u001b[0m, 0, 2, 1, 3) -> float32_295<1,14,16,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_295<1,14,16,32>\u001b[0m) -> float32_296<1,14,16,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_296<1,14,16,32>\u001b[0m) -> (int32_297<>\u001b[0m, int32_298<>\u001b[0m, \u001b[90mint32_299<>\u001b[0m, \u001b[90mint32_300<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_296<1,14,16,32>\u001b[0m, (int32_297<>\u001b[0m, int32_298<>\u001b[0m, -1)) -> float32_301<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mDebertaV2SelfOutput[tflite.deberta]\u001b[0m(float32_301<1,14,512>\u001b[0m, float32_128<1,14,512>\u001b[0m) -> float32_308<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_301<1,14,512>\u001b[0m) -> float32_304<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_301<1,14,512>\u001b[0m, float32_302<512,512>\u001b[0m, float32_303<512>\u001b[0m) -> float32_304<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_304<1,14,512>\u001b[0m, float32_128<1,14,512>\u001b[0m) -> float32_305<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(float32_305<1,14,512>\u001b[0m) -> float32_308<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_305<1,14,512>\u001b[0m, (512), \u001b[4mfloat32_306<512>\u001b[0m, \u001b[4mfloat32_307<512>\u001b[0m, 1e-07) -> float32_308<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_305<1,14,512>\u001b[0m, (512), float32_306<512>\u001b[0m, float32_307<512>\u001b[0m, 1e-07, True) -> float32_308<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDebertaV2Intermediate[tflite.deberta]\u001b[0m(float32_308<1,14,512>\u001b[0m) -> float32_312<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_308<1,14,512>\u001b[0m) -> float32_311<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_308<1,14,512>\u001b[0m, float32_309<512,512>\u001b[0m, float32_310<512>\u001b[0m) -> float32_311<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMish[torch.nn.modules.activation]\u001b[0m(float32_311<1,14,512>\u001b[0m) -> float32_312<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmish[torch.nn.functional]\u001b[0m(float32_311<1,14,512>\u001b[0m, inplace=False) -> float32_312<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mDebertaV2Output[tflite.models]\u001b[0m(float32_312<1,14,512>\u001b[0m, float32_308<1,14,512>\u001b[0m) -> float32_319<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_312<1,14,512>\u001b[0m, float32_308<1,14,512>\u001b[0m) -> float32_313<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_313<1,14,512>\u001b[0m) -> float32_316<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_313<1,14,512>\u001b[0m, float32_314<576,512>\u001b[0m, float32_315<576>\u001b[0m) -> float32_316<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(float32_316<1,14,576>\u001b[0m) -> float32_319<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_316<1,14,576>\u001b[0m, (576), \u001b[4mfloat32_317<576>\u001b[0m, \u001b[4mfloat32_318<576>\u001b[0m, 1e-07) -> float32_319<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_316<1,14,576>\u001b[0m, (576), float32_317<576>\u001b[0m, float32_318<576>\u001b[0m, 1e-07, True) -> float32_319<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mDebertaV2Encoder[tflite.deberta]\u001b[0m(float32_319<1,14,576>\u001b[0m, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> {\"last_hidden_state\": \u001b[90mfloat32_494<1,14,576>\u001b[0m, \"hidden_states\": (\u001b[90mfloat32_319<1,14,576>\u001b[0m, \u001b[90mfloat32_494<1,14,576>\u001b[0m)}\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(\u001b[4mfloat32_320<50,576>\u001b[0m) -> float32_323<50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_320<50,576>\u001b[0m, (576), \u001b[4mfloat32_321<576>\u001b[0m, \u001b[4mfloat32_322<576>\u001b[0m, 1e-07) -> float32_323<50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_320<50,576>\u001b[0m, (576), float32_321<576>\u001b[0m, float32_322<576>\u001b[0m, 1e-07, True) -> float32_323<50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mDebertaV2Layer[tflite.deberta]\u001b[0m(float32_319<1,14,576>\u001b[0m, query_states=None, relative_pos=None, rel_embeddings=float32_323<50,576>\u001b[0m, output_attentions=False, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> float32_494<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDebertaV2Attention[tflite.deberta]\u001b[0m(float32_319<1,14,576>\u001b[0m, output_attentions=False, query_states=None, relative_pos=None, rel_embeddings=float32_323<50,576>\u001b[0m, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> float32_483<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDisentangledSelfAttention[tflite.deberta]\u001b[0m(float32_319<1,14,576>\u001b[0m, False, query_states=None, relative_pos=None, rel_embeddings=float32_323<50,576>\u001b[0m, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> float32_476<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_319<1,14,576>\u001b[0m) -> float32_326<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_319<1,14,576>\u001b[0m, float32_324<576,576>\u001b[0m, float32_325<576>\u001b[0m) -> float32_326<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_326<1,14,576>\u001b[0m) -> (int32_327<>\u001b[0m, int32_328<>\u001b[0m, \u001b[90mint32_329<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_326<1,14,576>\u001b[0m, (int32_327<>\u001b[0m, int32_328<>\u001b[0m, 16, -1)) -> float32_330<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_330<1,14,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_331<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_331<1,16,14,36>\u001b[0m) -> float32_332<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_330<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_333<>\u001b[0m, int32_334<>\u001b[0m, \u001b[90mint32_335<>\u001b[0m, \u001b[90mint32_336<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_330<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_337<>\u001b[0m, \u001b[90mint32_338<>\u001b[0m, \u001b[90mint32_339<>\u001b[0m, int32_340<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_332<1,16,14,36>\u001b[0m, -1, int32_334<>\u001b[0m, int32_340<>\u001b[0m) -> float32_341<16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_319<1,14,576>\u001b[0m) -> float32_344<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_319<1,14,576>\u001b[0m, float32_342<576,576>\u001b[0m, float32_343<576>\u001b[0m) -> float32_344<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_344<1,14,576>\u001b[0m) -> (int32_345<>\u001b[0m, int32_346<>\u001b[0m, \u001b[90mint32_347<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_344<1,14,576>\u001b[0m, (int32_345<>\u001b[0m, int32_346<>\u001b[0m, 16, -1)) -> float32_348<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_348<1,14,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_349<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_349<1,16,14,36>\u001b[0m) -> float32_350<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_348<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_351<>\u001b[0m, int32_352<>\u001b[0m, \u001b[90mint32_353<>\u001b[0m, \u001b[90mint32_354<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_348<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_355<>\u001b[0m, \u001b[90mint32_356<>\u001b[0m, \u001b[90mint32_357<>\u001b[0m, int32_358<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_350<1,16,14,36>\u001b[0m, -1, int32_352<>\u001b[0m, int32_358<>\u001b[0m) -> float32_359<16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_319<1,14,576>\u001b[0m) -> float32_362<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_319<1,14,576>\u001b[0m, float32_360<576,576>\u001b[0m, float32_361<576>\u001b[0m) -> float32_362<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_362<1,14,576>\u001b[0m) -> (int32_363<>\u001b[0m, int32_364<>\u001b[0m, \u001b[90mint32_365<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_362<1,14,576>\u001b[0m, (int32_363<>\u001b[0m, int32_364<>\u001b[0m, 16, -1)) -> float32_366<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_366<1,14,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_367<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_367<1,16,14,36>\u001b[0m) -> float32_368<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_366<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_369<>\u001b[0m, int32_370<>\u001b[0m, \u001b[90mint32_371<>\u001b[0m, \u001b[90mint32_372<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_366<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_373<>\u001b[0m, \u001b[90mint32_374<>\u001b[0m, \u001b[90mint32_375<>\u001b[0m, int32_376<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_368<1,16,14,36>\u001b[0m, -1, int32_370<>\u001b[0m, int32_376<>\u001b[0m) -> float32_377<16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_378<>\u001b[0m, 3) -> float32_379<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msqrt[torch]\u001b[0m(float32_379<>\u001b[0m) -> float32_380<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_359<16,14,36>\u001b[0m, -1, -2) -> float32_381<16,36,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_341<16,14,36>\u001b[0m, float32_381<16,36,14>\u001b[0m) -> float32_382<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_382<16,14,14>\u001b[0m, float32_380<>\u001b[0m) -> float32_383<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_323<50,576>\u001b[0m, (0:50, :)) -> float32_384<50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_384<50,576>\u001b[0m, 0) -> float32_385<1,50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*Linear[torch.nn.modules.linear]\u001b[0m(float32_385<1,50,576>\u001b[0m) -> float32_386<1,50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_386<1,50,576>\u001b[0m) -> (int32_387<>\u001b[0m, int32_388<>\u001b[0m, \u001b[90mint32_389<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_386<1,50,576>\u001b[0m, (int32_387<>\u001b[0m, int32_388<>\u001b[0m, 16, -1)) -> float32_390<1,50,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_390<1,50,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_391<1,16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_391<1,16,50,36>\u001b[0m) -> float32_392<1,16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_390<1,50,16,36>\u001b[0m) -> (\u001b[90mint32_393<>\u001b[0m, int32_394<>\u001b[0m, \u001b[90mint32_395<>\u001b[0m, \u001b[90mint32_396<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_390<1,50,16,36>\u001b[0m) -> (\u001b[90mint32_397<>\u001b[0m, \u001b[90mint32_398<>\u001b[0m, \u001b[90mint32_399<>\u001b[0m, int32_400<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_392<1,16,50,36>\u001b[0m, -1, int32_394<>\u001b[0m, int32_400<>\u001b[0m) -> float32_401<16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*Linear[torch.nn.modules.linear]\u001b[0m(float32_385<1,50,576>\u001b[0m) -> float32_402<1,50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_402<1,50,576>\u001b[0m) -> (int32_403<>\u001b[0m, int32_404<>\u001b[0m, \u001b[90mint32_405<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_402<1,50,576>\u001b[0m, (int32_403<>\u001b[0m, int32_404<>\u001b[0m, 16, -1)) -> float32_406<1,50,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_406<1,50,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_407<1,16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_407<1,16,50,36>\u001b[0m) -> float32_408<1,16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_406<1,50,16,36>\u001b[0m) -> (\u001b[90mint32_409<>\u001b[0m, int32_410<>\u001b[0m, \u001b[90mint32_411<>\u001b[0m, \u001b[90mint32_412<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_406<1,50,16,36>\u001b[0m) -> (\u001b[90mint32_413<>\u001b[0m, \u001b[90mint32_414<>\u001b[0m, \u001b[90mint32_415<>\u001b[0m, int32_416<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_408<1,16,50,36>\u001b[0m, -1, int32_410<>\u001b[0m, int32_416<>\u001b[0m) -> float32_417<16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_378<>\u001b[0m, 3) -> float32_418<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msqrt[torch]\u001b[0m(float32_418<>\u001b[0m) -> float32_419<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_417<16,50,36>\u001b[0m, -1, -2) -> float32_420<16,36,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_341<16,14,36>\u001b[0m, float32_420<16,36,50>\u001b[0m) -> float32_421<16,14,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_421<16,14,50>\u001b[0m) -> (int32_422<>\u001b[0m, int32_423<>\u001b[0m, \u001b[90mint32_424<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_421<16,14,50>\u001b[0m, -1) -> float32_425<11200>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSelector[tflite.deberta]\u001b[0m(float32_425<11200>\u001b[0m, int32_142<3136>\u001b[0m) -> float32_427<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mlong[torch.Tensor]\u001b[0m(int32_142<3136>\u001b[0m) -> int64_426<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_425<11200>\u001b[0m, 0, int64_426<3136>\u001b[0m) -> float32_427<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_427<3136>\u001b[0m, int32_422<>\u001b[0m, int32_423<>\u001b[0m, int32_423<>\u001b[0m) -> float32_428<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_428<16,14,14>\u001b[0m, float32_419<>\u001b[0m) -> float32_429<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__radd__[torch.Tensor]\u001b[0m(float32_429<16,14,14>\u001b[0m, 0) -> float32_430<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_378<>\u001b[0m, 3) -> float32_431<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msqrt[torch]\u001b[0m(float32_431<>\u001b[0m) -> float32_432<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_401<16,50,36>\u001b[0m, -1, -2) -> float32_433<16,36,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_359<16,14,36>\u001b[0m, float32_433<16,36,50>\u001b[0m) -> float32_434<16,14,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_434<16,14,50>\u001b[0m) -> (int32_435<>\u001b[0m, int32_436<>\u001b[0m, \u001b[90mint32_437<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_434<16,14,50>\u001b[0m, -1) -> float32_438<11200>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSelector[tflite.deberta]\u001b[0m(float32_438<11200>\u001b[0m, int32_144<3136>\u001b[0m) -> float32_440<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mlong[torch.Tensor]\u001b[0m(int32_144<3136>\u001b[0m) -> int64_439<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_438<11200>\u001b[0m, 0, int64_439<3136>\u001b[0m) -> float32_440<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_440<3136>\u001b[0m, int32_435<>\u001b[0m, int32_436<>\u001b[0m, int32_436<>\u001b[0m) -> float32_441<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_441<16,14,14>\u001b[0m, -1, -2) -> float32_442<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_442<16,14,14>\u001b[0m, float32_432<>\u001b[0m) -> float32_443<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_430<16,14,14>\u001b[0m, float32_443<16,14,14>\u001b[0m) -> float32_430<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_383<16,14,14>\u001b[0m, float32_430<16,14,14>\u001b[0m) -> float32_444<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_444<16,14,14>\u001b[0m) -> (\u001b[90mint32_445<>\u001b[0m, int32_446<>\u001b[0m, \u001b[90mint32_447<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_444<16,14,14>\u001b[0m) -> (\u001b[90mint32_448<>\u001b[0m, \u001b[90mint32_449<>\u001b[0m, int32_450<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_444<16,14,14>\u001b[0m, -1, 16, int32_446<>\u001b[0m, int32_450<>\u001b[0m) -> float32_451<1,16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch]\u001b[0m(float32_451<1,16,14,14>\u001b[0m, -1) -> float32_452<1,16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_452<1,16,14,14>\u001b[0m) -> (\u001b[90mint32_453<>\u001b[0m, \u001b[90mint32_454<>\u001b[0m, int32_455<>\u001b[0m, \u001b[90mint32_456<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_452<1,16,14,14>\u001b[0m) -> (\u001b[90mint32_457<>\u001b[0m, \u001b[90mint32_458<>\u001b[0m, \u001b[90mint32_459<>\u001b[0m, int32_460<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_452<1,16,14,14>\u001b[0m, -1, int32_455<>\u001b[0m, int32_460<>\u001b[0m) -> float32_461<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_461<16,14,14>\u001b[0m, float32_377<16,14,36>\u001b[0m) -> float32_462<16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_462<16,14,36>\u001b[0m) -> (\u001b[90mint32_463<>\u001b[0m, int32_464<>\u001b[0m, \u001b[90mint32_465<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_462<16,14,36>\u001b[0m) -> (\u001b[90mint32_466<>\u001b[0m, \u001b[90mint32_467<>\u001b[0m, int32_468<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_462<16,14,36>\u001b[0m, -1, 16, int32_464<>\u001b[0m, int32_468<>\u001b[0m) -> float32_469<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_469<1,16,14,36>\u001b[0m, 0, 2, 1, 3) -> float32_470<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_470<1,14,16,36>\u001b[0m) -> float32_471<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_471<1,14,16,36>\u001b[0m) -> (int32_472<>\u001b[0m, int32_473<>\u001b[0m, \u001b[90mint32_474<>\u001b[0m, \u001b[90mint32_475<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_471<1,14,16,36>\u001b[0m, (int32_472<>\u001b[0m, int32_473<>\u001b[0m, -1)) -> float32_476<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mDebertaV2SelfOutput[tflite.deberta]\u001b[0m(float32_476<1,14,576>\u001b[0m, float32_319<1,14,576>\u001b[0m) -> float32_483<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_476<1,14,576>\u001b[0m) -> float32_479<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_476<1,14,576>\u001b[0m, float32_477<576,576>\u001b[0m, float32_478<576>\u001b[0m) -> float32_479<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_479<1,14,576>\u001b[0m, float32_319<1,14,576>\u001b[0m) -> float32_480<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(float32_480<1,14,576>\u001b[0m) -> float32_483<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_480<1,14,576>\u001b[0m, (576), \u001b[4mfloat32_481<576>\u001b[0m, \u001b[4mfloat32_482<576>\u001b[0m, 1e-07) -> float32_483<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_480<1,14,576>\u001b[0m, (576), float32_481<576>\u001b[0m, float32_482<576>\u001b[0m, 1e-07, True) -> float32_483<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDebertaV2Intermediate[tflite.deberta]\u001b[0m(float32_483<1,14,576>\u001b[0m) -> float32_487<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_483<1,14,576>\u001b[0m) -> float32_486<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_483<1,14,576>\u001b[0m, float32_484<576,576>\u001b[0m, float32_485<576>\u001b[0m) -> float32_486<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMish[torch.nn.modules.activation]\u001b[0m(float32_486<1,14,576>\u001b[0m) -> float32_487<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmish[torch.nn.functional]\u001b[0m(float32_486<1,14,576>\u001b[0m, inplace=False) -> float32_487<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mDebertaV2Output[tflite.models]\u001b[0m(float32_487<1,14,576>\u001b[0m, float32_483<1,14,576>\u001b[0m) -> float32_494<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_487<1,14,576>\u001b[0m, float32_483<1,14,576>\u001b[0m) -> float32_488<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_488<1,14,576>\u001b[0m) -> float32_491<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_488<1,14,576>\u001b[0m, float32_489<576,576>\u001b[0m, float32_490<576>\u001b[0m) -> float32_491<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(float32_491<1,14,576>\u001b[0m) -> float32_494<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_491<1,14,576>\u001b[0m, (576), \u001b[4mfloat32_492<576>\u001b[0m, \u001b[4mfloat32_493<576>\u001b[0m, 1e-07) -> float32_494<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_491<1,14,576>\u001b[0m, (576), float32_492<576>\u001b[0m, float32_493<576>\u001b[0m, 1e-07, True) -> float32_494<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mDebertaV2Encoder[tflite.deberta]\u001b[0m(float32_494<1,14,576>\u001b[0m, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> {\"last_hidden_state\": float32_669<1,14,512>\u001b[0m, \"hidden_states\": (\u001b[90mfloat32_494<1,14,576>\u001b[0m, float32_669<1,14,512>\u001b[0m)}\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(\u001b[4mfloat32_495<50,576>\u001b[0m) -> float32_498<50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_495<50,576>\u001b[0m, (576), \u001b[4mfloat32_496<576>\u001b[0m, \u001b[4mfloat32_497<576>\u001b[0m, 1e-07) -> float32_498<50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_495<50,576>\u001b[0m, (576), float32_496<576>\u001b[0m, float32_497<576>\u001b[0m, 1e-07, True) -> float32_498<50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mDebertaV2Layer[tflite.deberta]\u001b[0m(float32_494<1,14,576>\u001b[0m, query_states=None, relative_pos=None, rel_embeddings=float32_498<50,576>\u001b[0m, output_attentions=False, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> float32_669<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDebertaV2Attention[tflite.deberta]\u001b[0m(float32_494<1,14,576>\u001b[0m, output_attentions=False, query_states=None, relative_pos=None, rel_embeddings=float32_498<50,576>\u001b[0m, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> float32_658<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDisentangledSelfAttention[tflite.deberta]\u001b[0m(float32_494<1,14,576>\u001b[0m, False, query_states=None, relative_pos=None, rel_embeddings=float32_498<50,576>\u001b[0m, ids=int32_142<3136>\u001b[0m, ids_t=int32_144<3136>\u001b[0m) -> float32_651<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_494<1,14,576>\u001b[0m) -> float32_501<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_494<1,14,576>\u001b[0m, float32_499<576,576>\u001b[0m, float32_500<576>\u001b[0m) -> float32_501<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_501<1,14,576>\u001b[0m) -> (int32_502<>\u001b[0m, int32_503<>\u001b[0m, \u001b[90mint32_504<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_501<1,14,576>\u001b[0m, (int32_502<>\u001b[0m, int32_503<>\u001b[0m, 16, -1)) -> float32_505<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_505<1,14,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_506<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_506<1,16,14,36>\u001b[0m) -> float32_507<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_505<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_508<>\u001b[0m, int32_509<>\u001b[0m, \u001b[90mint32_510<>\u001b[0m, \u001b[90mint32_511<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_505<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_512<>\u001b[0m, \u001b[90mint32_513<>\u001b[0m, \u001b[90mint32_514<>\u001b[0m, int32_515<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_507<1,16,14,36>\u001b[0m, -1, int32_509<>\u001b[0m, int32_515<>\u001b[0m) -> float32_516<16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_494<1,14,576>\u001b[0m) -> float32_519<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_494<1,14,576>\u001b[0m, float32_517<576,576>\u001b[0m, float32_518<576>\u001b[0m) -> float32_519<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_519<1,14,576>\u001b[0m) -> (int32_520<>\u001b[0m, int32_521<>\u001b[0m, \u001b[90mint32_522<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_519<1,14,576>\u001b[0m, (int32_520<>\u001b[0m, int32_521<>\u001b[0m, 16, -1)) -> float32_523<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_523<1,14,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_524<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_524<1,16,14,36>\u001b[0m) -> float32_525<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_523<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_526<>\u001b[0m, int32_527<>\u001b[0m, \u001b[90mint32_528<>\u001b[0m, \u001b[90mint32_529<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_523<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_530<>\u001b[0m, \u001b[90mint32_531<>\u001b[0m, \u001b[90mint32_532<>\u001b[0m, int32_533<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_525<1,16,14,36>\u001b[0m, -1, int32_527<>\u001b[0m, int32_533<>\u001b[0m) -> float32_534<16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_494<1,14,576>\u001b[0m) -> float32_537<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_494<1,14,576>\u001b[0m, float32_535<576,576>\u001b[0m, float32_536<576>\u001b[0m) -> float32_537<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_537<1,14,576>\u001b[0m) -> (int32_538<>\u001b[0m, int32_539<>\u001b[0m, \u001b[90mint32_540<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_537<1,14,576>\u001b[0m, (int32_538<>\u001b[0m, int32_539<>\u001b[0m, 16, -1)) -> float32_541<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_541<1,14,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_542<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_542<1,16,14,36>\u001b[0m) -> float32_543<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_541<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_544<>\u001b[0m, int32_545<>\u001b[0m, \u001b[90mint32_546<>\u001b[0m, \u001b[90mint32_547<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_541<1,14,16,36>\u001b[0m) -> (\u001b[90mint32_548<>\u001b[0m, \u001b[90mint32_549<>\u001b[0m, \u001b[90mint32_550<>\u001b[0m, int32_551<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_543<1,16,14,36>\u001b[0m, -1, int32_545<>\u001b[0m, int32_551<>\u001b[0m) -> float32_552<16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_553<>\u001b[0m, 3) -> float32_554<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msqrt[torch]\u001b[0m(float32_554<>\u001b[0m) -> float32_555<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_534<16,14,36>\u001b[0m, -1, -2) -> float32_556<16,36,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_516<16,14,36>\u001b[0m, float32_556<16,36,14>\u001b[0m) -> float32_557<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_557<16,14,14>\u001b[0m, float32_555<>\u001b[0m) -> float32_558<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[torch.Tensor]\u001b[0m(float32_498<50,576>\u001b[0m, (0:50, :)) -> float32_559<50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_559<50,576>\u001b[0m, 0) -> float32_560<1,50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*Linear[torch.nn.modules.linear]\u001b[0m(float32_560<1,50,576>\u001b[0m) -> float32_561<1,50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_561<1,50,576>\u001b[0m) -> (int32_562<>\u001b[0m, int32_563<>\u001b[0m, \u001b[90mint32_564<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_561<1,50,576>\u001b[0m, (int32_562<>\u001b[0m, int32_563<>\u001b[0m, 16, -1)) -> float32_565<1,50,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_565<1,50,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_566<1,16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_566<1,16,50,36>\u001b[0m) -> float32_567<1,16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_565<1,50,16,36>\u001b[0m) -> (\u001b[90mint32_568<>\u001b[0m, int32_569<>\u001b[0m, \u001b[90mint32_570<>\u001b[0m, \u001b[90mint32_571<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_565<1,50,16,36>\u001b[0m) -> (\u001b[90mint32_572<>\u001b[0m, \u001b[90mint32_573<>\u001b[0m, \u001b[90mint32_574<>\u001b[0m, int32_575<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_567<1,16,50,36>\u001b[0m, -1, int32_569<>\u001b[0m, int32_575<>\u001b[0m) -> float32_576<16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*Linear[torch.nn.modules.linear]\u001b[0m(float32_560<1,50,576>\u001b[0m) -> float32_577<1,50,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_577<1,50,576>\u001b[0m) -> (int32_578<>\u001b[0m, int32_579<>\u001b[0m, \u001b[90mint32_580<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_577<1,50,576>\u001b[0m, (int32_578<>\u001b[0m, int32_579<>\u001b[0m, 16, -1)) -> float32_581<1,50,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_581<1,50,16,36>\u001b[0m, 0, 2, 1, 3) -> float32_582<1,16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_582<1,16,50,36>\u001b[0m) -> float32_583<1,16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_581<1,50,16,36>\u001b[0m) -> (\u001b[90mint32_584<>\u001b[0m, int32_585<>\u001b[0m, \u001b[90mint32_586<>\u001b[0m, \u001b[90mint32_587<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_581<1,50,16,36>\u001b[0m) -> (\u001b[90mint32_588<>\u001b[0m, \u001b[90mint32_589<>\u001b[0m, \u001b[90mint32_590<>\u001b[0m, int32_591<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_583<1,16,50,36>\u001b[0m, -1, int32_585<>\u001b[0m, int32_591<>\u001b[0m) -> float32_592<16,50,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_553<>\u001b[0m, 3) -> float32_593<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msqrt[torch]\u001b[0m(float32_593<>\u001b[0m) -> float32_594<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_592<16,50,36>\u001b[0m, -1, -2) -> float32_595<16,36,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_516<16,14,36>\u001b[0m, float32_595<16,36,50>\u001b[0m) -> float32_596<16,14,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_596<16,14,50>\u001b[0m) -> (int32_597<>\u001b[0m, int32_598<>\u001b[0m, \u001b[90mint32_599<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_596<16,14,50>\u001b[0m, -1) -> float32_600<11200>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSelector[tflite.deberta]\u001b[0m(float32_600<11200>\u001b[0m, int32_142<3136>\u001b[0m) -> float32_602<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mlong[torch.Tensor]\u001b[0m(int32_142<3136>\u001b[0m) -> int64_601<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_600<11200>\u001b[0m, 0, int64_601<3136>\u001b[0m) -> float32_602<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_602<3136>\u001b[0m, int32_597<>\u001b[0m, int32_598<>\u001b[0m, int32_598<>\u001b[0m) -> float32_603<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_603<16,14,14>\u001b[0m, float32_594<>\u001b[0m) -> float32_604<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__radd__[torch.Tensor]\u001b[0m(float32_604<16,14,14>\u001b[0m, 0) -> float32_605<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_553<>\u001b[0m, 3) -> float32_606<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msqrt[torch]\u001b[0m(float32_606<>\u001b[0m) -> float32_607<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_576<16,50,36>\u001b[0m, -1, -2) -> float32_608<16,36,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_534<16,14,36>\u001b[0m, float32_608<16,36,50>\u001b[0m) -> float32_609<16,14,50>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_609<16,14,50>\u001b[0m) -> (int32_610<>\u001b[0m, int32_611<>\u001b[0m, \u001b[90mint32_612<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_609<16,14,50>\u001b[0m, -1) -> float32_613<11200>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSelector[tflite.deberta]\u001b[0m(float32_613<11200>\u001b[0m, int32_144<3136>\u001b[0m) -> float32_615<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mlong[torch.Tensor]\u001b[0m(int32_144<3136>\u001b[0m) -> int64_614<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_613<11200>\u001b[0m, 0, int64_614<3136>\u001b[0m) -> float32_615<3136>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_615<3136>\u001b[0m, int32_610<>\u001b[0m, int32_611<>\u001b[0m, int32_611<>\u001b[0m) -> float32_616<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_616<16,14,14>\u001b[0m, -1, -2) -> float32_617<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_617<16,14,14>\u001b[0m, float32_607<>\u001b[0m) -> float32_618<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_605<16,14,14>\u001b[0m, float32_618<16,14,14>\u001b[0m) -> float32_605<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_558<16,14,14>\u001b[0m, float32_605<16,14,14>\u001b[0m) -> float32_619<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_619<16,14,14>\u001b[0m) -> (\u001b[90mint32_620<>\u001b[0m, int32_621<>\u001b[0m, \u001b[90mint32_622<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_619<16,14,14>\u001b[0m) -> (\u001b[90mint32_623<>\u001b[0m, \u001b[90mint32_624<>\u001b[0m, int32_625<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_619<16,14,14>\u001b[0m, -1, 16, int32_621<>\u001b[0m, int32_625<>\u001b[0m) -> float32_626<1,16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch]\u001b[0m(float32_626<1,16,14,14>\u001b[0m, -1) -> float32_627<1,16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_627<1,16,14,14>\u001b[0m) -> (\u001b[90mint32_628<>\u001b[0m, \u001b[90mint32_629<>\u001b[0m, int32_630<>\u001b[0m, \u001b[90mint32_631<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_627<1,16,14,14>\u001b[0m) -> (\u001b[90mint32_632<>\u001b[0m, \u001b[90mint32_633<>\u001b[0m, \u001b[90mint32_634<>\u001b[0m, int32_635<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_627<1,16,14,14>\u001b[0m, -1, int32_630<>\u001b[0m, int32_635<>\u001b[0m) -> float32_636<16,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_636<16,14,14>\u001b[0m, float32_552<16,14,36>\u001b[0m) -> float32_637<16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_637<16,14,36>\u001b[0m) -> (\u001b[90mint32_638<>\u001b[0m, int32_639<>\u001b[0m, \u001b[90mint32_640<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_637<16,14,36>\u001b[0m) -> (\u001b[90mint32_641<>\u001b[0m, \u001b[90mint32_642<>\u001b[0m, int32_643<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_637<16,14,36>\u001b[0m, -1, 16, int32_639<>\u001b[0m, int32_643<>\u001b[0m) -> float32_644<1,16,14,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_644<1,16,14,36>\u001b[0m, 0, 2, 1, 3) -> float32_645<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcontiguous[torch.Tensor]\u001b[0m(float32_645<1,14,16,36>\u001b[0m) -> float32_646<1,14,16,36>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco.funcs]\u001b[0m(float32_646<1,14,16,36>\u001b[0m) -> (int32_647<>\u001b[0m, int32_648<>\u001b[0m, \u001b[90mint32_649<>\u001b[0m, \u001b[90mint32_650<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_646<1,14,16,36>\u001b[0m, (int32_647<>\u001b[0m, int32_648<>\u001b[0m, -1)) -> float32_651<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mDebertaV2SelfOutput[tflite.deberta]\u001b[0m(float32_651<1,14,576>\u001b[0m, float32_494<1,14,576>\u001b[0m) -> float32_658<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_651<1,14,576>\u001b[0m) -> float32_654<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_651<1,14,576>\u001b[0m, float32_652<576,576>\u001b[0m, float32_653<576>\u001b[0m) -> float32_654<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_654<1,14,576>\u001b[0m, float32_494<1,14,576>\u001b[0m) -> float32_655<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(float32_655<1,14,576>\u001b[0m) -> float32_658<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_655<1,14,576>\u001b[0m, (576), \u001b[4mfloat32_656<576>\u001b[0m, \u001b[4mfloat32_657<576>\u001b[0m, 1e-07) -> float32_658<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_655<1,14,576>\u001b[0m, (576), float32_656<576>\u001b[0m, float32_657<576>\u001b[0m, 1e-07, True) -> float32_658<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDebertaV2Intermediate[tflite.deberta]\u001b[0m(float32_658<1,14,576>\u001b[0m) -> float32_662<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_658<1,14,576>\u001b[0m) -> float32_661<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_658<1,14,576>\u001b[0m, float32_659<576,576>\u001b[0m, float32_660<576>\u001b[0m) -> float32_661<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMish[torch.nn.modules.activation]\u001b[0m(float32_661<1,14,576>\u001b[0m) -> float32_662<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmish[torch.nn.functional]\u001b[0m(float32_661<1,14,576>\u001b[0m, inplace=False) -> float32_662<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mDebertaV2Output[tflite.models]\u001b[0m(float32_662<1,14,576>\u001b[0m, float32_658<1,14,576>\u001b[0m) -> float32_669<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_662<1,14,576>\u001b[0m, float32_658<1,14,576>\u001b[0m) -> float32_663<1,14,576>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_663<1,14,576>\u001b[0m) -> float32_666<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_663<1,14,576>\u001b[0m, float32_664<512,576>\u001b[0m, float32_665<512>\u001b[0m) -> float32_666<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mLayerNorm[torch.nn.modules.normalization]\u001b[0m(float32_666<1,14,512>\u001b[0m) -> float32_669<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mlayer_norm[torch.nn.functional]\u001b[0m(float32_666<1,14,512>\u001b[0m, (512), \u001b[4mfloat32_667<512>\u001b[0m, \u001b[4mfloat32_668<512>\u001b[0m, 1e-07) -> float32_669<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlayer_norm[torch]\u001b[0m(float32_666<1,14,512>\u001b[0m, (512), float32_667<512>\u001b[0m, float32_668<512>\u001b[0m, 1e-07, True) -> float32_669<1,14,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mmean[torch.Tensor]\u001b[0m(float32_669<1,14,512>\u001b[0m, 1) -> float32_670<1,512>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_670<1,512>\u001b[0m) -> float32_673<1,250>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_670<1,512>\u001b[0m, float32_671<250,512>\u001b[0m, float32_672<250>\u001b[0m) -> float32_673<1,250>\u001b[0m\n",
      "\n",
      "\n",
      "Conversion complete. Elapsed time: 10.73 sec.\n"
     ]
    }
   ],
   "source": [
    "keras_model = nobuco.pytorch_to_keras(\n",
    "    model,\n",
    "    args=[inp],\n",
    "    input_shapes={inp: (None, 5, 100)},\n",
    "    inputs_channel_order=ChannelOrder.PYTORCH,\n",
    "    outputs_channel_order=ChannelOrder.TENSORFLOW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.56it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in tqdm(range(100)):\n",
    "    path = df['path'][i]\n",
    "    pq, data = load_relevant_data_subset(path)\n",
    "    x = prepro_tf(data)\n",
    "    y = keras_model(x)\n",
    "    preds.append(y.numpy()[0])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(df['target'].head(len(preds)), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepro + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFLiteModel(tf.keras.Model):\n",
    "    def __init__(self, prepro, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "        self.prepro = prepro\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n",
    "    def call(self, inputs=None):\n",
    "        x = self.prepro(tf.cast(inputs, dtype=tf.float32))\n",
    "        y = self.model(x)\n",
    "\n",
    "        return {'outputs': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_tf = PreprocessingTF(type_embed, max_len=MAX_LENS[config.processed_folder], model_max_len=config.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_keras_model = TFLiteModel(prepro_tf, keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 49.90it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "# for i in tqdm(range(len(df['path']))):\n",
    "for i in tqdm(range(1000)):\n",
    "    path = df['path'][i]\n",
    "    name = f\"{path.split('/')[-2]}_{path.split('/')[-1].split('.')[0]}.npy\"\n",
    "\n",
    "    pq, data = load_relevant_data_subset(path)\n",
    "\n",
    "    y = tflite_keras_model(data)\n",
    "    \n",
    "    preds.append(y['outputs'].numpy()[0])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/kaggle_islr/src/utils/metrics.py:21\u001b[0m, in \u001b[0;36maccuracy\u001b[0;34m(labels, predictions, beta)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(predictions\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     19\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "accuracy(df['target'].head(len(preds)), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 14:38:35.000913: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:35.001109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_lite_model_4/244713' with dtype int32 and shape [1000]\n",
      "\t [[{{node tf_lite_model_4/244713}}]]\n",
      "2023-04-27 14:38:35.526329: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,543,3]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-27 14:38:35.526522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '245238' with dtype int32 and shape [1000]\n",
      "\t [[{{node 245238}}]]\n",
      "2023-04-27 14:38:35.580323: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,543,3]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-27 14:38:35.580505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '245267' with dtype int32 and shape [1000]\n",
      "\t [[{{node 245267}}]]\n",
      "2023-04-27 14:38:40.308674: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,100]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.505372: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,100]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.590929: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [1,?,100,19]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.600632: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [1,?,100,48]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.646025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.659959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.688320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.703281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.717254: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.741443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.788754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.806577: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.879511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.888797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.906599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.915963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.967281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:40.984974: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.010255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.020556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.038344: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.047641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.098081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.115381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.140255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.149505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.168556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.177802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.398806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.398958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'preprocessing_tf_5/250823' with dtype int32 and shape [1000]\n",
      "\t [[{{node preprocessing_tf_5/250823}}]]\n",
      "2023-04-27 14:38:41.468322: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.468468: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'preprocessing_tf_5/250852' with dtype int32 and shape [1000]\n",
      "\t [[{{node preprocessing_tf_5/250852}}]]\n",
      "2023-04-27 14:38:41.554783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.554979: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'preprocessing_tf_5/250884' with dtype int32 and shape [1000]\n",
      "\t [[{{node preprocessing_tf_5/250884}}]]\n",
      "2023-04-27 14:38:41.615126: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.615302: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '250911' with dtype int32 and shape [1000]\n",
      "\t [[{{node 250911}}]]\n",
      "2023-04-27 14:38:41.793005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.793179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'preprocessing_tf_5/250942' with dtype int32 and shape [1000]\n",
      "\t [[{{node preprocessing_tf_5/250942}}]]\n",
      "2023-04-27 14:38:41.852508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:41.852677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '250969' with dtype int32 and shape [1000]\n",
      "\t [[{{node 250969}}]]\n",
      "2023-04-27 14:38:42.020377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:42.020565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '250998' with dtype int32 and shape [1000]\n",
      "\t [[{{node 250998}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 14:38:42.194552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:42.194734: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '251027' with dtype int32 and shape [1000]\n",
      "\t [[{{node 251027}}]]\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 14:38:42.690650: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:42.690865: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '251058' with dtype int32 and shape [1000]\n",
      "\t [[{{node 251058}}]]\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "2023-04-27 14:38:43.465375: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,543,3]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-27 14:38:43.465599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '251087' with dtype int32 and shape [1000]\n",
      "\t [[{{node 251087}}]]\n",
      "2023-04-27 14:38:45.404833: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,100]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:45.642045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,100]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:50.157542: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [1,?,100,19]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:50.206702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [1,?,100,48]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:50.524708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:50.570143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:50.904042: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:50.944537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:50.985252: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:51.149623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:51.275798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:51.344177: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:52.399033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:52.461926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:52.537788: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:52.581901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:52.733216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:52.797446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:52.966088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:53.041278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:53.135880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:53.192519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:53.377054: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:53.456152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:53.629082: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:53.702431: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:53.791659: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-27 14:38:53.846672: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,576]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
      "2023-04-27 14:38:54.556299: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node serving_default_inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../logs/2023-04-24/9/model_keras/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../logs/2023-04-24/9/model_keras/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    }
   ],
   "source": [
    "tflite_keras_model.save(EXP_FOLDER + 'model_keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 14:39:09.782232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_inputs' with dtype float and shape [?,543,3]\n",
      "\t [[{{node serving_default_inputs}}]]\n",
      "2023-04-27 14:39:10.869505: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-04-27 14:39:10.869578: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-04-27 14:39:10.870895: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: ../logs/2023-04-24/9/model_keras\n",
      "2023-04-27 14:39:10.915262: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-04-27 14:39:10.915325: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: ../logs/2023-04-24/9/model_keras\n",
      "2023-04-27 14:39:11.060293: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-04-27 14:39:11.548775: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: ../logs/2023-04-24/9/model_keras\n",
      "2023-04-27 14:39:11.746054: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 875162 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(EXP_FOLDER + \"model_keras\")\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# converter.target_spec.supported_ops = [\n",
    "#     tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "#     tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "# ]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(EXP_FOLDER + 'model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tflite_runtime.interpreter import Interpreter\n",
    "\n",
    "interpreter = Interpreter(EXP_FOLDER + \"model.tflite\")\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=data)\n",
    "output['outputs'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:16<00:00, 59.04it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "times = []\n",
    "# for i in tqdm(range(len(df['path']))):\n",
    "for i in tqdm(range(1000)):\n",
    "    path = df['path'][i]\n",
    "    name = f\"{path.split('/')[-2]}_{path.split('/')[-1].split('.')[0]}.npy\"\n",
    "\n",
    "    pq, data = load_relevant_data_subset(path)\n",
    "\n",
    "    t0 = time.time()\n",
    "    output = prediction_fn(inputs=data)\n",
    "    t1 = time.time()\n",
    "\n",
    "    preds.append(output['outputs'])\n",
    "    times.append((t1 - t0) * 1000)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(df['target'].head(len(preds)), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(df['target'].head(len(preds)), pred_val[:len(preds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Runtime : 1.3ms\n"
     ]
    }
   ],
   "source": [
    "print(f'-> Runtime : {np.mean(times) :.1f}ms')\n",
    "\n",
    "if np.mean(times) > 100:\n",
    "    print(\"\\n WARNING ! Runtime must be < 100 ms !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Runtime : 30.9ms\n"
     ]
    }
   ],
   "source": [
    "print(f'-> Runtime : {np.mean(times) :.1f}ms')\n",
    "\n",
    "if np.mean(times) > 100:\n",
    "    print(\"\\n WARNING ! Runtime must be < 100 ms !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size & upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model size : 13.448 Mo\n"
     ]
    }
   ],
   "source": [
    "size = os.path.getsize(EXP_FOLDER + 'model.tflite') / np.power(1024, 2)\n",
    "print(f\"-> Model size : {size:.3f} Mo\")\n",
    "\n",
    "assert size < 40, \"Model size must be < 40 Mo !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Copying ../logs/2023-04-24/9/ ...\n",
      "\n",
      "Dataset size : 0.236 Go\n",
      "- Update existing dataset !\n",
      "- Uploading ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39.0M/39.0M [00:10<00:00, 4.02MB/s]\n",
      "100%|██████████| 27.2M/27.2M [00:06<00:00, 4.66MB/s]\n",
      "100%|██████████| 22.0/22.0 [00:01<00:00, 12.6B/s]\n",
      "100%|██████████| 28.5M/28.5M [00:06<00:00, 4.40MB/s]\n",
      "100%|██████████| 20.4M/20.4M [00:04<00:00, 5.29MB/s]\n",
      "100%|██████████| 13.4M/13.4M [00:02<00:00, 5.31MB/s]\n",
      "100%|██████████| 35.8M/35.8M [00:09<00:00, 4.15MB/s]\n",
      "100%|██████████| 28.5M/28.5M [00:06<00:00, 4.63MB/s]\n",
      "100%|██████████| 10.0M/10.0M [00:02<00:00, 3.80MB/s]\n",
      "100%|██████████| 39.0M/39.0M [00:13<00:00, 2.92MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output :\n",
      " b'Starting upload for file ens_nobuco2_model.tflite\\nUpload successful: ens_nobuco2_model.tflite (39MB)\\nStarting upload for file 2023-04-17_42_model.tflite\\nUpload successful: 2023-04-17_42_model.tflite (27MB)\\nStarting upload for file .ipynb_checkpoints.zip\\nUpload successful: .ipynb_checkpoints.zip (22B)\\nStarting upload for file 2023-04-12_18_model.tflite\\nUpload successful: 2023-04-12_18_model.tflite (28MB)\\nStarting upload for file 2023-04-18_10_model.tflite\\nUpload successful: 2023-04-18_10_model.tflite (20MB)\\nStarting upload for file 2023-04-24_9_model.tflite\\nUpload successful: 2023-04-24_9_model.tflite (13MB)\\nStarting upload for file ens_distilled_model.tflite\\nUpload successful: ens_distilled_model.tflite (36MB)\\nStarting upload for file 2023-04-13_29_model.tflite\\nUpload successful: 2023-04-13_29_model.tflite (28MB)\\nStarting upload for file 2023-04-12_2_model.tflite\\nUpload successful: 2023-04-12_2_model.tflite (10MB)\\nStarting upload for file ens_nobuco1_model.tflite\\nUpload successful: ens_nobuco1_model.tflite (39MB)\\nDataset version is being created. Please check progress at https://www.kaggle.com/theoviel/islr-models\\n'\n",
      "\n",
      "Error :\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "upload_to_kaggle([EXP_FOLDER], \"/workspace/datasets/islr_weights_1/\", \"ISLR Models\", update_folders=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
