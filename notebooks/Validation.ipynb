{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to validate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.preparation import *\n",
    "from data.dataset import SignDataset\n",
    "\n",
    "from utils.metrics import *\n",
    "from utils.plots import *\n",
    "from utils.logger import Config\n",
    "\n",
    "from inference.main import kfold_inference_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(DATA_PATH, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP_FOLDER = \"../logs/2023-04-17/42/\"  # 0.7265 / x5 0.7273 / MTx10 0.7274\n",
    "# EXP_FOLDER = \"../logs/2023-04-18/10/\"  # 0.7245 / x5 0.7247 / MTx10 0.7249\n",
    "# EXP_FOLDER = \"../logs/2023-04-19/6/\"  # 0.7245 / x10 0.7254 / MTx10 0.7254\n",
    "# EXP_FOLDER = \"../logs/2023-04-20/18/\"  # 0.7247 / x10 0.7254 / MTx10 0.7256\n",
    "# EXP_FOLDER = \"../logs/2023-04-20/19/\"  # 0.7250 / x10 0.7257 / MTx10 0.7254\n",
    "# EXP_FOLDER = \"../logs/2023-04-20/21/\"  # 0.7243 / x10 0.7246 / MTx10 0.7244\n",
    "\n",
    "FILES = [  #  CV 0.7279 - LB 0.78\n",
    "    \"../logs/2023-04-14/37/pred_oof_dist.npy\",  # 0.7225 / Dist 0.7196 (-0.003)\n",
    "    \"../logs/2023-04-15/7/pred_oof_dist.npy\",  # 0.7228 / Dist 0.7176 (-0.005)\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7340 - LB 0.78\n",
    "    \"../logs/2023-04-20/19/pred_oof_inf.npy\",  # 0.7257\n",
    "    \"../logs/2023-04-20/18/pred_oof_mt.npy\",  # 0.7254\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7400 - LB 0.78\n",
    "    \"../logs/2023-04-22/7/pred_oof_mt.npy\",  # 0.7310\n",
    "    \"../logs/2023-04-23/28/pred_oof_dist.npy\",  # 0.7348\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7439  - 0.78\n",
    "    \"../logs/2023-04-25/71/pred_oof_dist.npy\",  # 0.7329 / torch_12\n",
    "    \"../logs/2023-04-28/7/pred_oof_dist.npy\",  # 0.7359 / torch_19\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7438 - 0.79\n",
    "    \"../logs/2023-04-28/5/pred_oof_dist_soup.npy\",  # 0.7329 / torch_12\n",
    "    \"../logs/2023-04-28/7/pred_oof_dist_soup.npy\",  # 0.7359 / torch_19\n",
    "]\n",
    "\n",
    "# FILES = [  # CV 0.7459\n",
    "#     \"../logs/2023-04-28/5/pred_oof_dist_soup.npy\",  # 0.7329 / torch_12\n",
    "#     \"../logs/2023-04-28/6/pred_oof_dist_soup.npy\",  # 0.7338 / torch_15 s\n",
    "#     \"../logs/2023-04-28/7/pred_oof_dist_soup.npy\",  # 0.7359 / torch_19\n",
    "# ]\n",
    "\n",
    "\n",
    "FILES = [  # CV 0.7400 - LB 0.78\n",
    "#     \"../logs/2023-04-22/7/pred_oof_mt.npy\",  # 0.7310\n",
    "#     \"../logs/2023-04-23/28/pred_oof_dist.npy\",  # 0.7348\n",
    "#     \"../logs/2023-04-25/71/pred_oof_dist.npy\",  # 0.7352  \n",
    "\n",
    "\n",
    "#     \"../logs/2023-04-23/28/pred_oof_dist.npy\",  # DISTx10 0.7348  torch_16\n",
    "\n",
    "#     \"../logs/2023-04-26/0/pred_oof_dist.npy\",  # DISTx10 0.7359   torch_16\n",
    "#     \"../logs/2023-04-26/3/pred_oof_dist.npy\",  # DIST 0.7355      torch_16\n",
    "    \n",
    "#     \"../logs/2023-04-27/14/pred_oof_dist.npy\",  # 0.7328 /  torch_15\n",
    "#     \"../logs/2023-04-27/15/pred_oof_dist.npy\",  # 0.7304 /  torch_12\n",
    "#     \"../logs/2023-04-27/17/pred_oof_dist.npy\",  # 0.7329 /  torch_18  -> SUB\n",
    "\n",
    "#     \"../logs/2023-04-27/19/pred_oof_dist_soup.npy\",  # 0.7341 /  torch_15  -> SUB\n",
    "#     \"../logs/2023-04-27/19/pred_oof_dist.npy\",  # 0.7334 /  torch_15  -> SUB\n",
    "#     \"../logs/2023-04-27/20/pred_oof_dist.npy\",  # 0.7328 /  torch_12\n",
    "\n",
    "#     \"../logs/2023-04-28/4/pred_oof_dist_soup.npy\",  # 0.7351 / torch_15\n",
    "#     \"../logs/2023-04-28/4/pred_oof_dist.npy\",  # 0.7336 / torch_15\n",
    "    \n",
    "#      \"../logs/2023-04-28/5/pred_oof_dist_soup.npy\",  # 0.7329 / torch_12\n",
    "#     \"../logs/2023-04-28/5/pred_oof_dist.npy\",  # 0.7321 / torch_12\n",
    "    \n",
    "#     \"../logs/2023-04-28/6/pred_oof_dist_soup.npy\",  # 0.7338 / torch_15 s\n",
    "#     \"../logs/2023-04-28/6/pred_oof_dist.npy\",  # 0.7336 / torch_15 s\n",
    "    \n",
    "#     \"../logs/2023-04-28/7/pred_oof_dist_soup.npy\",  # 0.7359 / torch_19\n",
    "    \"../logs/2023-04-28/7/pred_oof_dist.npy\",  # 0.7356 / torch_19\n",
    "]\n",
    "\n",
    "WEIGHTS = [1, 1, 1]\n",
    "\n",
    "if len(WEIGHTS) == len(FILES):\n",
    "    pred_oof = np.average([np.load(f) for f in FILES], weights=WEIGHTS, axis=0)\n",
    "    print('- Weighted average')\n",
    "else:\n",
    "    print('- Simple average')\n",
    "    pred_oof = np.mean([np.load(f) for f in FILES], 0)\n",
    "\n",
    "df['pred'] = pred_oof.argmax(-1)\n",
    "\n",
    "score = accuracy(df['target'], pred_oof)\n",
    "print(f\"\\n-> CV acc : {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = [  # CV 0.7400 - LB 0.78\n",
    "    # BIG\n",
    "#     \"../logs/2023-04-23/28/pred_oof_dist.npy\",  # 0.7348\n",
    "\n",
    "#     \"../logs/2023-04-23/28/pred_oof_dist.npy\",  # DISTx10 0.7348  torch_16\n",
    "    \"../logs/2023-04-25/71/pred_oof_dist.npy\", # DIST 0.7352  torch_12\n",
    "    \"../logs/2023-04-26/0/pred_oof_dist.npy\",  # DIST 0.7359  torch_16\n",
    "    \"../logs/2023-04-26/3/pred_oof_dist.npy\",  # DIST 0.7355  torch_16\n",
    "    \n",
    "    # SMALLER\n",
    "    \n",
    "    \"../logs/2023-04-27/14/pred_oof_dist.npy\",  # 0.7328 /  torch_15\n",
    "    \"../logs/2023-04-27/17/pred_oof_dist.npy\",  # 0.7329 /  torch_18\n",
    "\n",
    "#     \"../logs/2023-04-27/19/pred_oof_dist_soup.npy\",  # 0.7341 /  torch_15\n",
    "    \"../logs/2023-04-27/19/pred_oof_dist.npy\",  # 0.7334 /  torch_15\n",
    "\n",
    "    \"../logs/2023-04-27/20/pred_oof_dist.npy\",  # 0.7328 /  torch_12\n",
    "\n",
    "#     \"../logs/2023-04-28/4/pred_oof_dist_soup.npy\",  # 0.7351 / torch_15\n",
    "    \"../logs/2023-04-28/4/pred_oof_dist.npy\",  # 0.7336 / torch_15\n",
    "    \n",
    "#      \"../logs/2023-04-28/5/pred_oof_dist_soup.npy\",  # 0.7329 / torch_12\n",
    "    \"../logs/2023-04-28/5/pred_oof_dist.npy\",  # 0.7321 / torch_12\n",
    "    \n",
    "#     \"../logs/2023-04-28/6/pred_oof_dist_soup.npy\",  # 0.7338 / torch_15 s\n",
    "    \"../logs/2023-04-28/6/pred_oof_dist.npy\",  # 0.7336 / torch_15 s\n",
    "    \n",
    "#     \"../logs/2023-04-28/7/pred_oof_dist_soup.npy\",  # 0.7359 / torch_19\n",
    "    \"../logs/2023-04-28/7/pred_oof_dist.npy\",  # 0.7356 / torch_19\n",
    "]\n",
    "\n",
    "FILES_ = [np.load(f) for f in tqdm(FILES)]\n",
    "\n",
    "already_found = []\n",
    "for i, f1 in enumerate(tqdm(FILES_)):\n",
    "    for j, f2 in enumerate(FILES_):\n",
    "\n",
    "        pred_oof = (f1 + f2) / 2\n",
    "        score = accuracy(df['target'], pred_oof)\n",
    "        if score > 0.7435:\n",
    "            found = \" \".join(sorted([FILES[i], FILES[j]]))\n",
    "\n",
    "            if found not in already_found:\n",
    "                already_found.append(found)\n",
    "                print(f\"\\n-> CV acc : {score:.4f}  - {found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = [  # CV 0.7400 - LB 0.78\n",
    "    # BIG\n",
    "#     \"../logs/2023-04-23/28/pred_oof_dist.npy\",  # 0.7348\n",
    "#     \"../logs/2023-04-25/71/pred_oof_dist.npy\",  # 0.7353\n",
    "#     \"../logs/2023-04-23/28/pred_oof_dist.npy\",  # DISTx10 0.7348  torch_16\n",
    "#     \"../logs/2023-04-25/71/pred_oof_dist.npy\", # DISTx10  0.7353  torch_12\n",
    "#     \"../logs/2023-04-26/0/pred_oof_dist.npy\",  # DISTx10 0.7359   torch_16\n",
    "#     \"../logs/2023-04-26/3/pred_oof_dist.npy\",  # DIST 0.7355      torch_16\n",
    "    \n",
    "    # SMALLER\n",
    "    \n",
    "    \"../logs/2023-04-27/14/pred_oof_dist.npy\",  # 0.7328 /  torch_15\n",
    "#     \"../logs/2023-04-27/17/pred_oof_dist.npy\",  # 0.7329 /  torch_18\n",
    "\n",
    "    \"../logs/2023-04-27/19/pred_oof_dist_soup.npy\",  # 0.7341 /  torch_15\n",
    "#     \"../logs/2023-04-27/19/pred_oof_dist.npy\",  # 0.7334 /  torch_15\n",
    "\n",
    "    \"../logs/2023-04-27/20/pred_oof_dist.npy\",  # 0.7328 /  torch_12\n",
    "\n",
    "    \"../logs/2023-04-28/4/pred_oof_dist_soup.npy\",  # 0.7351 / torch_15\n",
    "#     \"../logs/2023-04-28/4/pred_oof_dist.npy\",  # 0.7336 / torch_15\n",
    "    \n",
    "     \"../logs/2023-04-28/5/pred_oof_dist_soup.npy\",  # 0.7329 / torch_12\n",
    "#     \"../logs/2023-04-28/5/pred_oof_dist.npy\",  # 0.7321 / torch_12\n",
    "    \n",
    "    \"../logs/2023-04-28/6/pred_oof_dist_soup.npy\",  # 0.7338 / torch_15 s\n",
    "#     \"../logs/2023-04-28/6/pred_oof_dist.npy\",  # 0.7336 / torch_15 s\n",
    "    \n",
    "    \"../logs/2023-04-28/7/pred_oof_dist_soup.npy\",  # 0.7359 / torch_19\n",
    "#     \"../logs/2023-04-28/7/pred_oof_dist.npy\",  # 0.7356 / torch_19\n",
    "]\n",
    "\n",
    "FILES_ = [np.load(f) for f in tqdm(FILES)]\n",
    "\n",
    "# for i, f1 in enumerate(tqdm(FILES_)):\n",
    "#     for j, f2 in enumerate(FILES_):\n",
    "#         pred_oof = (f1 + f2) / 2\n",
    "#         score = accuracy(df['target'], pred_oof)\n",
    "#         if score > 0.743:\n",
    "#             print(f\"\\n-> CV acc : {score:.4f}  - {FILES[i]} - {FILES[j]}\")\n",
    "\n",
    "already_found = []\n",
    "for i, f1 in enumerate(tqdm(FILES_)):\n",
    "    for j, f2 in enumerate(FILES_):\n",
    "        for k, f3 in enumerate(FILES_):\n",
    "            pred_oof = (f1 + f2 + f3) / 3\n",
    "            score = accuracy(df['target'], pred_oof)\n",
    "            if score > 0.746:\n",
    "                found = \" \".join(sorted([FILES[i], FILES[j], FILES[k]]))\n",
    "                \n",
    "                if found not in already_found:\n",
    "                    already_found.append(found)\n",
    "                    print(f\"\\n-> CV acc : {score:.4f}  - {found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = \"../logs/2023-04-21/31/\"  # 0.7267\n",
    "# EXP_FOLDER = \"../logs/2023-04-22/2/\"  # 0.7310\n",
    "EXP_FOLDER = \"../logs/2023-04-23/28/\"  # 0.7348 dist\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-25/66/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(DATA_PATH, config.processed_folder)\n",
    "df = prepare_data(DATA_PATH, \"torch_15/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df = df.merge(folds, how=\"left\", on=[\"participant_id\", \"sequence_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_oof = np.load(EXP_FOLDER + \"pred_oof.npy\")\n",
    "# pred_oof = np.load(EXP_FOLDER + \"pred_oof_dist.npy\")\n",
    "\n",
    "df['pred'] = pred_oof.argmax(-1)\n",
    "\n",
    "score = accuracy(df['target'], pred_oof)\n",
    "print(f\"-> CV acc : {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SignDataset(df, max_len=None)\n",
    "# dataset.fill_buffer(tqdm_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = [len(v) for v in tqdm(dataset.buffer.values())]\n",
    "# # np.save('../output/lens.npy', np.array(lens))\n",
    "# # lens = np.load('../output/lens.npy')\n",
    "# df['len'] = lens\n",
    "\n",
    "# sns.countplot(x=lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['error'] = (df['target'] != df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_40'] = np.load(\"../logs/2023-04-27/14/pred_oof_dist.npy\").argmax(-1)  # 0.7328 /  torch_15\n",
    "df['pred_80'] = np.load(\"../logs/2023-04-27/17/pred_oof_dist.npy\").argmax(-1)  # 0.7329 /  torch_18\n",
    "df['pred_20'] = np.load(\"../logs/2023-04-27/20/pred_oof_dist.npy\").argmax(-1)  # 0.7328 /  torch_12\n",
    "\n",
    "df['error_40'] = (df['target'] != df['pred_40'])\n",
    "df['error_80'] = (df['target'] != df['pred_80'])\n",
    "df['error_20'] = (df['target'] != df['pred_20'])\n",
    "\n",
    "df['error_20'].mean(), df['error_40'].mean(), df['error_80'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfg = df.groupby('participant_id').agg(['mean', 'count', 'sum'])[['error']]\n",
    "# dfg.sort_values(('error',  'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['len'] > 80).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['len'] = np.clip(df['len'] // 10 * 10 + 10, 0, 200)\n",
    "df['len'] = np.clip(df['len'], 0, 100)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=df['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df.groupby('len').agg(['mean', 'sum'])[['error_20', 'error_40', 'error_80']]\n",
    "# dfg.sort_values(('error',  'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(dfg.index, dfg[('error_20', 'mean')], label=\"20\", marker=\"x\")\n",
    "plt.scatter(dfg.index, dfg[('error_40', 'mean')], label=\"40\", marker=\"x\")\n",
    "plt.scatter(dfg.index, dfg[('error_80', 'mean')], label=\"80\", marker=\"x\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 80\n",
    "\n",
    "szs = []\n",
    "divs = []\n",
    "for sz in range(200):\n",
    "    div = int((((sz - max_len) > 0) * (sz / max_len) + 1))\n",
    "    divs.append(div)\n",
    "    szs.append(sz // div)\n",
    "    \n",
    "    \n",
    "# plt.plot(szs, label=\"size\")\n",
    "plt.plot(divs, label=\"stride\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfg = df.groupby('len').agg(['mean', 'count', 'sum'])[['error']]\n",
    "# dfg.sort_values(('error',  'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df.groupby('sign').agg('mean')[['error']].sort_values('error', ascending=False).T\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = json.load(open(DATA_PATH + \"sign_to_prediction_index_map.json\", \"r\"))\n",
    "classes = list(classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df['target'], df['pred'], normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(classes))):  # gt\n",
    "    for j in range(len(classes)):\n",
    "        n = cm[i, j]\n",
    "        if n > 50 and i != j:\n",
    "            s = f\"{classes[i]} predicted as {classes[j]} :\".ljust(32)\n",
    "            print(f\"{s} {n} / {cm[i].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(50, 50))\n",
    "# plot_confusion_matrix(df['pred'], df['target'], display_labels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inf val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = \"../logs/2023-04-23/27/\"   # 0.7302 / DIST 0.7324 / DISTx10 0.7327\n",
    "# EXP_FOLDER = \"../logs/2023-04-23/28/\"   # 0.7295 / DIST 0.7341 / DISTx10 0.7348\n",
    "\n",
    "# EXP_FOLDER = \"../logs/2023-04-25/66/\"  # 0.7321 / x10  0.7315  / MTx10 0.7319\n",
    "EXP_FOLDER = \"../logs/2023-04-25/71/\" # 0.7322 / DIST 0.7352 / DISTx10 0.7353\n",
    "EXP_FOLDER = \"../logs/2023-04-26/0/\"  # 0.7317 / DIST 0.7353 / DISTx10 0.7359\n",
    "EXP_FOLDER = \"../logs/2023-04-26/3/\"  # 0.7338 / DIST 0.7355 / DISTx10 0.7351\n",
    "\n",
    "# # Smaller dist\n",
    "# EXP_FOLDER = \"../logs/2023-04-27/14/\" #  0.7319 / DIST 0.7328 /   torch_15\n",
    "# EXP_FOLDER = \"../logs/2023-04-27/15/\" #  0.7307 / DIST 0.7304 /   torch_12\n",
    "# EXP_FOLDER = \"../logs/2023-04-27/17/\" #  0.7322 / DIST 0.7329 /   torch_18\n",
    "# EXP_FOLDER = \"../logs/2023-04-27/19/\" #  0.7328 / DIST 0.7334 / DISTx10 0.7341   torch_15\n",
    "# # EXP_FOLDER = \"../logs/2023-04-27/20/\" #  0.7316 / DIST 0.7328 /   torch_12\n",
    "\n",
    "# # EXP_FOLDER = \"../logs/2023-04-28/4/\"  #  0.7343 / DIST 0.7336 / DISTx10 0.7351    torch_15\n",
    "# EXP_FOLDER = \"../logs/2023-04-28/5/\"  #  0.7321 / DIST 0.7321 / DISTx10 0.7329    torch_12\n",
    "# EXP_FOLDER = \"../logs/2023-04-28/6/\"  #  0.7338 / DIST 0.7335 / DISTx10 0.7338    torch_15 s\n",
    "# EXP_FOLDER = \"../logs/2023-04-28/7/\"  #  0.7342 / DIST 0.7356 / DISTx10 0.7359    torch_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", \"r\")))\n",
    "df = prepare_data(DATA_PATH, config.processed_folder)\n",
    "\n",
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df = df.merge(folds, how=\"left\", on=[\"participant_id\", \"sequence_id\"])\n",
    "    \n",
    "try:\n",
    "    pred_oof = np.load(EXP_FOLDER + \"pred_oof.npy\")\n",
    "    df['pred'] = pred_oof.argmax(-1)\n",
    "\n",
    "    score = accuracy(df['target'], pred_oof)\n",
    "    print(f\"-> CV acc : {score:.4f}\")\n",
    "except:\n",
    "    df = df[df['fold'] == 0].reset_index(drop=True)\n",
    "    \n",
    "    pred_oof = np.load(EXP_FOLDER + \"pred_val_0.npy\")\n",
    "    df['pred'] = pred_oof.argmax(-1)\n",
    "\n",
    "    score = accuracy(df['target'], pred_oof)\n",
    "    print(f\"-> Fold 0 acc : {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_oof = kfold_inference_val(\n",
    "    df,\n",
    "    EXP_FOLDER,\n",
    "    debug=False,\n",
    "    save=True,\n",
    "    use_fp16=True,\n",
    "    use_mt=False,\n",
    "    distilled=True,\n",
    "    n_soup=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inf train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = \"../logs/2023-04-11/27/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", \"r\")))\n",
    "df = prepare_data(DATA_PATH, config.processed_folder)\n",
    "\n",
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df = df.merge(folds, how=\"left\", on=[\"participant_id\", \"sequence_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_oof = kfold_inference_val(\n",
    "    df,\n",
    "    EXP_FOLDER,\n",
    "    debug=False,\n",
    "    save=False,\n",
    "    use_fp16=True,\n",
    "    train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(EXP_FOLDER + \"pred_oof_train.npy\", pred_oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_0'] = pred_oof[0].argmax(-1)\n",
    "df_val = df[df['fold'] != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err = df_val[(df_val['target'] != df_val['pred_0'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SignDataset(df_err, max_len=None, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "#     i = 92284\n",
    "    data = dataset[i]\n",
    "    \n",
    "#     for k in data.keys():\n",
    "#         print(k, data[k].size())\n",
    "    \n",
    "    print(df_err['sequence_id'][i], \"- pred :\", classes[df_err['pred_0'][i]], \" - truth :\", df_err['sign'][i])\n",
    "    plot_sample_with_edges(data, n_frames=4, figsize=(10, 10), show_text=False)\n",
    "\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
