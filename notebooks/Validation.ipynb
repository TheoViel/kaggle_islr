{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to validate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.preparation import *\n",
    "from data.dataset import SignDataset\n",
    "\n",
    "from utils.metrics import *\n",
    "from utils.plots import *\n",
    "from utils.logger import Config\n",
    "\n",
    "from inference.main import kfold_inference_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(DATA_PATH, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP_FOLDER = \"../logs/2023-04-17/42/\"  # 0.7265 / x5 0.7273 / MTx10 0.7274\n",
    "# EXP_FOLDER = \"../logs/2023-04-18/10/\"  # 0.7245 / x5 0.7247 / MTx10 0.7249\n",
    "# EXP_FOLDER = \"../logs/2023-04-19/6/\"  # 0.7245 / x10 0.7254 / MTx10 0.7254\n",
    "# EXP_FOLDER = \"../logs/2023-04-20/18/\"  # 0.7247 / x10 0.7254 / MTx10 0.7256\n",
    "# EXP_FOLDER = \"../logs/2023-04-20/19/\"  # 0.7250 / x10 0.7257 / MTx10 0.7254\n",
    "# EXP_FOLDER = \"../logs/2023-04-20/21/\"  # 0.7243 / x10 0.7246 / MTx10 0.7244\n",
    "\n",
    "FILES = [  #  CV 0.7279 - LB 0.78\n",
    "    \"../logs/2023-04-14/37/pred_oof_dist.npy\",  # 0.7225 / Dist 0.7196 (-0.003)\n",
    "    \"../logs/2023-04-15/7/pred_oof_dist.npy\",  # 0.7228 / Dist 0.7176 (-0.005)\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7340 - LB 0.78\n",
    "    \"../logs/2023-04-20/19/pred_oof_inf.npy\",  # 0.7257\n",
    "    \"../logs/2023-04-20/18/pred_oof_mt.npy\",  # 0.7254\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7400 - LB 0.78\n",
    "    \"../logs/2023-04-22/7/pred_oof_mt.npy\",  # 0.7310\n",
    "    \"../logs/2023-04-23/28/pred_oof_dist.npy\",  # 0.7348\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7439  - 0.78\n",
    "    \"../logs/2023-04-25/71/pred_oof_dist.npy\",  # 0.7329 / torch_12\n",
    "    \"../logs/2023-04-28/7/pred_oof_dist.npy\",  # 0.7359 / torch_19\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7438 - 0.79\n",
    "    \"../logs/2023-04-28/5/pred_oof_dist_soup.npy\",  # 0.7329 / torch_12\n",
    "    \"../logs/2023-04-28/7/pred_oof_dist_soup.npy\",  # 0.7359 / torch_19\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7446 - 0.79+\n",
    "    \"../logs/2023-04-27/17/pred_oof_dist_soup.npy\",   # 0.7331  torch_18 576\n",
    "    \"../logs/2023-04-28/9/pred_oof_dist_soup.npy\" ,   # 0.7366  torch_12 768\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7444 - 0.79++\n",
    "    \"../logs/2023-04-28/9/pred_oof_dist_soup.npy\" ,   # 0.7366  torch_12 768\n",
    "    \"../logs/2023-04-29/0/pred_oof_dist_soup.npy\",    # 0.7355  torch_19 640\n",
    "]\n",
    "\n",
    "FILES = [  # CV 0.7479 - 0.79++  640-60_768-25n (name is wrong)\n",
    "    \"../logs/2023-04-28/7/pred_oof_dist_soup.npy\" ,   # 0.7359  torch_19 576\n",
    "    \"../logs/2023-04-30/7/pred_oof_dist_soup.npy\",    # 0.7402  torch_12 768 mix norm\n",
    "]\n",
    "\n",
    "\n",
    "# FILES = [  # CV 0.7400 - LB 0.78\n",
    "# #     \"../logs/2023-04-27/14/pred_oof_dist_soup.npy\",   # 0.7334  torch_15 576\n",
    "# #     \"../logs/2023-04-27/15/pred_oof_dist_soup.npy\",   # 0.7311  torch_12 576\n",
    "# #     \"../logs/2023-04-27/17/pred_oof_dist_soup.npy\",   # 0.7331  torch_18 576\n",
    "# #     \"../logs/2023-04-27/19/pred_oof_dist_soup.npy\",   # 0.7341  torch_15 576\n",
    "#     \"../logs/2023-04-27/20/pred_oof_dist_soup.npy\",   # 0.7330  torch_12 576\n",
    "# #     \"../logs/2023-04-28/4/pred_oof_dist_soup.npy\" ,   # 0.7351  torch_15 576\n",
    "# #     \"../logs/2023-04-28/5/pred_oof_dist_soup.npy\" ,   # 0.7329  torch_12 576\n",
    "#     \"../logs/2023-04-28/6/pred_oof_dist_soup.npy\" ,   # 0.7338  torch_15 512\n",
    "# #     \"../logs/2023-04-28/7/pred_oof_dist_soup.npy\" ,   # 0.7359  torch_19 576\n",
    "# #     \"../logs/2023-04-28/9/pred_oof_dist_soup.npy\" ,   # 0.7366  torch_12 768\n",
    "# #     \"../logs/2023-04-28/11/pred_oof_dist_soup.npy\",   # 0.7341  torch_16 576\n",
    "# #     \"../logs/2023-04-28/12/pred_oof_dist_soup.npy\",   # 0.7313  torch_12 576\n",
    "# #     \"../logs/2023-04-29/0/pred_oof_dist_soup.npy\",    # 0.7355  torch_19 640\n",
    "# #     \"../logs/2023-04-29/1/pred_oof_dist_soup.npy\",    # 0.7311  torch_19 704 x 2\n",
    "#     \"../logs/2023-04-29/2/pred_oof_dist_soup.npy\",    # 0.7334  torch_16 512\n",
    "# #     \"../logs/2023-04-29/3/pred_oof_dist_soup.npy\",    # 0.7303  torch_12 512\n",
    "# ]\n",
    "\n",
    "WEIGHTS = [1, 1]\n",
    "\n",
    "if len(WEIGHTS) == len(FILES):\n",
    "    pred_oof = np.average([np.load(f) for f in FILES], weights=WEIGHTS, axis=0)\n",
    "    print('- Weighted average')\n",
    "else:\n",
    "    print('- Simple average')\n",
    "    pred_oof = np.mean([np.load(f) for f in FILES], 0)\n",
    "\n",
    "df['pred'] = pred_oof.argmax(-1)\n",
    "\n",
    "score = accuracy(df['target'], pred_oof)\n",
    "print(f\"\\n-> CV acc : {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = [  # CV 0.7400 - LB 0.78\n",
    "    \"../logs/2023-04-27/14/pred_oof_dist_soup.npy\",   # 0.7334  torch_15 576\n",
    "#     \"../logs/2023-04-27/15/pred_oof_dist_soup.npy\",   # 0.7311  torch_12 576\n",
    "    \"../logs/2023-04-27/17/pred_oof_dist_soup.npy\",   # 0.7331  torch_18 576\n",
    "    \"../logs/2023-04-27/19/pred_oof_dist_soup.npy\",   # 0.7341  torch_15 576\n",
    "#     \"../logs/2023-04-27/20/pred_oof_dist_soup.npy\",   # 0.7330  torch_12 576\n",
    "    \"../logs/2023-04-28/4/pred_oof_dist_soup.npy\" ,   # 0.7351  torch_15 576\n",
    "#     \"../logs/2023-04-28/5/pred_oof_dist_soup.npy\" ,   # 0.7329  torch_12 576\n",
    "#     \"../logs/2023-04-28/6/pred_oof_dist_soup.npy\" ,   # 0.7338  torch_15 512\n",
    "    \"../logs/2023-04-28/7/pred_oof_dist_soup.npy\" ,   # 0.7359  torch_19 576\n",
    "    \"../logs/2023-04-28/9/pred_oof_dist_soup.npy\" ,   # 0.7366  torch_12 768\n",
    "    \"../logs/2023-04-28/11/pred_oof_dist_soup.npy\",   # 0.7341  torch_16 576\n",
    "#     \"../logs/2023-04-28/12/pred_oof_dist_soup.npy\",   # 0.7313  torch_12 576\n",
    "    \"../logs/2023-04-29/0/pred_oof_dist_soup.npy\",    # 0.7355  torch_19 640\n",
    "#     \"../logs/2023-04-29/1/pred_oof_dist_soup.npy\",    # 0.7311  torch_19 704 x 2\n",
    "#     \"../logs/2023-04-29/2/pred_oof_dist_soup.npy\",    # 0.7334  torch_16 512\n",
    "#     \"../logs/2023-04-29/3/pred_oof_dist_soup.npy\",    # 0.7303  torch_12 512\n",
    "#     \"../logs/2023-04-30/4/pred_oof_dist_soup.npy\",    # 0.7325  torch_12 576 mix\n",
    "    \"../logs/2023-04-30/5/pred_oof_dist_soup.npy\",    # 0.7348  torch_12 768 mix\n",
    "    \"../logs/2023-04-30/6/pred_oof_dist_soup.npy\",    # 0.7352  torch_19 640 mix\n",
    "    \"../logs/2023-04-30/7/pred_oof_dist_soup.npy\",    # 0.7402  torch_12 768 mix norm\n",
    "]\n",
    "\n",
    "FILES_ = [np.load(f) for f in tqdm(FILES)]\n",
    "\n",
    "already_found = []\n",
    "for i, f1 in enumerate(FILES_):\n",
    "    for j, f2 in enumerate(FILES_):\n",
    "\n",
    "        pred_oof = (f1 + f2) / 2\n",
    "        score = accuracy(df['target'], pred_oof)\n",
    "        if score > 0.747:\n",
    "            found = \" \".join(sorted([FILES[i], FILES[j]]))\n",
    "\n",
    "            if found not in already_found:\n",
    "                already_found.append(found)\n",
    "                print(f\"\\n-> CV acc : {score:.4f}  - {found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = \"../logs/2023-04-21/31/\"  # 0.7267\n",
    "# EXP_FOLDER = \"../logs/2023-04-22/2/\"  # 0.7310\n",
    "EXP_FOLDER = \"../logs/2023-04-23/28/\"  # 0.7348 dist\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-25/66/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(DATA_PATH, config.processed_folder)\n",
    "df = prepare_data(DATA_PATH, \"torch_15/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df = df.merge(folds, how=\"left\", on=[\"participant_id\", \"sequence_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_oof = np.load(EXP_FOLDER + \"pred_oof.npy\")\n",
    "# pred_oof = np.load(EXP_FOLDER + \"pred_oof_dist.npy\")\n",
    "\n",
    "df['pred'] = pred_oof.argmax(-1)\n",
    "\n",
    "score = accuracy(df['target'], pred_oof)\n",
    "print(f\"-> CV acc : {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SignDataset(df, max_len=None)\n",
    "# dataset.fill_buffer(tqdm_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = [len(v) for v in tqdm(dataset.buffer.values())]\n",
    "# # np.save('../output/lens.npy', np.array(lens))\n",
    "# # lens = np.load('../output/lens.npy')\n",
    "# df['len'] = lens\n",
    "\n",
    "# sns.countplot(x=lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['error'] = (df['target'] != df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = np.clip(df['len'] // 10 * 10 + 10, 0, 200)\n",
    "df['len'] = np.clip(df['len'], 0, 100)\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.countplot(x=df['len'])\n",
    "\n",
    "dfg = df.groupby('len').agg(['mean', 'sum'])[['error_20', 'error_40', 'error_80']]\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfg = df.groupby('len').agg(['mean', 'count', 'sum'])[['error']]\n",
    "# dfg.sort_values(('error',  'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df.groupby('sign').agg('mean')[['error']].sort_values('error', ascending=False).T\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = json.load(open(DATA_PATH + \"sign_to_prediction_index_map.json\", \"r\"))\n",
    "classes = list(classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df['target'], df['pred'], normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(classes))):  # gt\n",
    "    for j in range(len(classes)):\n",
    "        n = cm[i, j]\n",
    "        if n > 50 and i != j:\n",
    "            s = f\"{classes[i]} predicted as {classes[j]} :\".ljust(32)\n",
    "            print(f\"{s} {n} / {cm[i].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(50, 50))\n",
    "# plot_confusion_matrix(df['pred'], df['target'], display_labels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inf val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = \"../logs/2023-04-23/27/\"   # 0.7302 / DIST 0.7324 / DISTx10 0.7327\n",
    "# EXP_FOLDER = \"../logs/2023-04-23/28/\"   # 0.7295 / DIST 0.7341 / DISTx10 0.7348\n",
    "\n",
    "# EXP_FOLDER = \"../logs/2023-04-25/66/\"  # 0.7321 / x10  0.7315  / MTx10 0.7319\n",
    "EXP_FOLDER = \"../logs/2023-04-25/71/\" # 0.7322 / DIST 0.7352 / DISTx10 0.7353\n",
    "EXP_FOLDER = \"../logs/2023-04-26/0/\"  # 0.7317 / DIST 0.7353 / DISTx10 0.7359\n",
    "EXP_FOLDER = \"../logs/2023-04-26/3/\"  # 0.7338 / DIST 0.7355 / DISTx10 0.7351\n",
    "\n",
    "# # Smaller dist\n",
    "EXP_FOLDER = \"../logs/2023-04-27/14/\" # 0.7319 / DIST 0.7328 / DISTx10 0.7334  torch_15 576\n",
    "EXP_FOLDER = \"../logs/2023-04-27/15/\" # 0.7307 / DIST 0.7304 / DISTx10 0.7311  torch_12 576\n",
    "EXP_FOLDER = \"../logs/2023-04-27/17/\" # 0.7322 / DIST 0.7329 / DISTx10 0.7331  torch_18 576\n",
    "EXP_FOLDER = \"../logs/2023-04-27/19/\" # 0.7328 / DIST 0.7334 / DISTx10 0.7341  torch_15 576\n",
    "EXP_FOLDER = \"../logs/2023-04-27/20/\" # 0.7316 / DIST 0.7328 / DISTx10 0.7330  torch_12 576\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-28/4/\"  # 0.7343 / DIST 0.7336 / DISTx10 0.7351   torch_15 576\n",
    "EXP_FOLDER = \"../logs/2023-04-28/5/\"  # 0.7321 / DIST 0.7321 / DISTx10 0.7329   torch_12 576\n",
    "EXP_FOLDER = \"../logs/2023-04-28/6/\"  # 0.7338 / DIST 0.7335 / DISTx10 0.7338   torch_15 512\n",
    "EXP_FOLDER = \"../logs/2023-04-28/7/\"  # 0.7342 / DIST 0.7356 / DISTx10 0.7359   torch_19 576\n",
    "EXP_FOLDER = \"../logs/2023-04-28/9/\"  # 0.7323 / DIST 0.7359 / DISTx10 0.7366   torch_12 768\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-28/11/\" # 0.7334 / DIST 0.7336 / DISTx10 0.7341   torch_16 576\n",
    "EXP_FOLDER = \"../logs/2023-04-28/12/\" # 0.7269 / DIST 0.7309 / DISTx10 0.7313   torch_12 576\n",
    "\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-29/0/\"  # 0.7346  / DIST 0.7347 / DISTx10 0.7355  torch_19 640\n",
    "EXP_FOLDER = \"../logs/2023-04-29/1/\"  # 0.7355 / DIST 0.7303 / DISTx10 0.7311    torch_19 704 x 2\n",
    "EXP_FOLDER = \"../logs/2023-04-29/2/\"  # 0.7331/ DIST 0.7316 / DISTx10 0.7334    torch_16 512\n",
    "EXP_FOLDER = \"../logs/2023-04-29/3/\"  # 0.7329 / DIST 0.7294 / DISTx10 0.7303    torch_12 512\n",
    "\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-30/0/\"  # 0.7301 / DIST 0.xxxx / DISTx10 0.7292    torch_12 512 8h\n",
    "EXP_FOLDER = \"../logs/2023-04-30/1/\"  # 0.7306 / DIST 0.xxxx / DISTx10 0.7287    torch_12 512 8h\n",
    "EXP_FOLDER = \"../logs/2023-04-30/2/\"  # 0.7322 / DIST 0.xxxx / DISTx10 0.7304    torch_12 512 8h\n",
    "EXP_FOLDER = \"../logs/2023-04-30/3/\"  # 0.7343 / DIST 0.xxxx / DISTx10 0.7313    torch_12 576 35\n",
    "\n",
    "EXP_FOLDER = \"../logs/2023-04-30/4/\"  # 0.7335 / DIST 0.xxxx / DISTx10 0.7325    torch_12 576 mix\n",
    "EXP_FOLDER = \"../logs/2023-04-30/5/\"  # 0.7330 / DIST 0.xxxx / DISTx10 0.7348    torch_12 768 mix\n",
    "EXP_FOLDER = \"../logs/2023-04-30/6/\"  # 0.7335 / DIST 0.xxxx / DISTx10 0.7352    torch_16 640 mix\n",
    "EXP_FOLDER = \"../logs/2023-04-30/7/\"  # 0.7335 / DIST 0.xxxx / DISTx10 0.xxxx    torch_12 768 mix norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", \"r\")))\n",
    "df = prepare_data(DATA_PATH, config.processed_folder)\n",
    "\n",
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df = df.merge(folds, how=\"left\", on=[\"participant_id\", \"sequence_id\"])\n",
    "    \n",
    "try:\n",
    "    pred_oof = np.load(EXP_FOLDER + \"pred_oof.npy\")\n",
    "    df['pred'] = pred_oof.argmax(-1)\n",
    "\n",
    "    score = accuracy(df['target'], pred_oof)\n",
    "    print(f\"-> CV acc : {score:.4f}\")\n",
    "except:\n",
    "    df = df[df['fold'] == 0].reset_index(drop=True)\n",
    "    \n",
    "    pred_oof = np.load(EXP_FOLDER + \"pred_val_0.npy\")\n",
    "    df['pred'] = pred_oof.argmax(-1)\n",
    "\n",
    "    score = accuracy(df['target'], pred_oof)\n",
    "    print(f\"-> Fold 0 acc : {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_oof = kfold_inference_val(\n",
    "    df,\n",
    "    EXP_FOLDER,\n",
    "    debug=False,\n",
    "    save=True,\n",
    "    use_fp16=True,\n",
    "    use_mt=False,\n",
    "    distilled=True,\n",
    "    n_soup=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
